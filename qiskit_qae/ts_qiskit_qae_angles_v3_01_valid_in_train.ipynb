{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa8b1fa",
   "metadata": {},
   "source": [
    "# The Timeseries Quantum Autoencoder\n",
    "*TS QAE in Qiskit with angle encoding of TS sliding windows*\n",
    "\n",
    "By: Jacob Cybulski<br>\n",
    "Date: August 2023 - February 2024<br>\n",
    "Aims: The goal of this notebook is to build a Time Series Quantum Autoencoder, \n",
    "    a circuit which can compress a quantum state of a timeseries onto a smaller amount of qubits, \n",
    "    while retaining the information from the initial state.\n",
    "Methods: A QAE model from Qiskit Tutorial 12 has been adopted for time series processing. \n",
    "- Time series data was converted to a series of sliding windows.\n",
    "- Several approaches to TS data encoding were tested, i.e. unary, binary and anglular.\n",
    "- Angle encoding was eventually used, with values centered around H state, in the range of [-pi/2..pi/2]\n",
    "- The model featuring an input and encoder blocks only (followed by a swap test) was subsequently trained.\n",
    "- A decoder was then added for testing, and the circuit initialised with an optimum set of parameters from training.\n",
    "- Each test sample was then encoded into the full QAE circuit, which was executed using a state vector simulation.\n",
    "- State vectors of input and output data was then visualised and compared. \n",
    "\n",
    "Sources: \n",
    "1. Romero, Jonathan, Jonathan P. Olson, and Alan Aspuru-Guzik. 2017. “Quantum Autoencoders for Efficient Compression of Quantum Data.” Quantum Science and Technology 2 (4): 045001.\n",
    "2. Bravo-Prieto, Carlos, \"Quantum autoencoders with enhanced data encoding.\" Machine Learning: Science and Technology, 2, May 2021\n",
    "3. Qiskit Tutorial, https://qiskit.org/ecosystem/machine-learning/tutorials/12_quantum_autoencoder.html. *Based on [1].*\n",
    "4. Eugenia Anello, Denoising Autoencoder in Pytorch on MNIST dataset, Dataseries (Medium), Jun 28, 2021.\n",
    "5. Eugenia Anello, <a href=\"https://github.com/eugeniaring/Medium-Articles/blob/main/Pytorch/denAE.ipynb\">GitHub</a>, Jun 28, 2021.\n",
    "6. Phillip Lippe, Tutorial 9: Deep Autoencoders, UvA Deep Learning Tutorials, Fall 2022.\n",
    "\n",
    "Notes:\n",
    "- Refer to the end of the notebook for the log of changes\n",
    "- Algorithm by Romera was followed\n",
    "- Results of the enhanced algorithm by Bravo-Prieto could not be reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce40c7-6be0-491b-aa49-8c57d60f5d3a",
   "metadata": {},
   "source": [
    "## Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ee277-2ea4-4716-b247-636973761a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae59d7-fad8-4ea0-84c9-f5440615feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3484ba7-c1f6-4e83-8848-2515aaad2816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.Target import *\n",
    "from utils.Window import *\n",
    "from utils.Callback import *\n",
    "from utils.TS import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baacf28-0e4b-4e8b-8047-f7cbcc895227",
   "metadata": {},
   "source": [
    "## Prepare windowed TS data\n",
    "*Values need to be in [-1..+1] range*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133f230-6923-4081-9f2c-0455735fdb6f",
   "metadata": {},
   "source": [
    "### Prepare time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c7d81-3e43-4926-9cdd-92768ff230c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start random process\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "algorithm_globals.random_seed = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc6ab4-4bf3-4b57-aa87-2a1d83725854",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data settings\n",
    "samples = 80\n",
    "samples_hi_res = samples*2\n",
    "split = 0.75\n",
    "\n",
    "### Define the time series parameters\n",
    "#   wind_size: sliding window size (which may be the same as number of qubits)\n",
    "#   horizon:   the number of time events to look ahead (to forecast)\n",
    "wind_size = 8 # tested with: 6(-), 8(+), 9(-) 10(++)\n",
    "wind_step = 4\n",
    "horizon = 1\n",
    "scale = 1 # 2\n",
    "pan = 0 # -1\n",
    "\n",
    "### Noise level\n",
    "noise_org = 0.03\n",
    "noise_ts = 0.03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75929cda-cfb8-40cd-8d3b-f7a6c28dc26f",
   "metadata": {},
   "source": [
    "### Utility TS plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b41a6-3d24-4b24-82b7-4c0a849731de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot source data\n",
    "def qae_plot_source_data(\n",
    "    X_train, y_train, X_valid, y_valid,\n",
    "    add_markers=True,\n",
    "    label_suffix=['', '', ''],\n",
    "    xlabel='Range', ylabel='Target value (deltas)',\n",
    "    title=f'Differenced TS Windows for Training and Validation',\n",
    "    sel_wind=None):\n",
    "\n",
    "    # Plot the original time series\n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    # plt.xlim(lb, ub)\n",
    "\n",
    "    # Plot target function\n",
    "    plt.plot([xt[0] for xt in X_train], [y[0] for y in y_train], color='blue', label='Training')\n",
    "    plt.plot([xv[0] for xv in X_valid], [y[0] for y in y_valid], color='red', label='Validation')\n",
    "    if sel_wind != None:\n",
    "        plt.plot(X_train[sel_wind], y_train[sel_wind], color='magenta', label='Window '+str(sel_wind))\n",
    "    if add_markers:\n",
    "        plt.plot([xt[0] for xt in X_train], [y[0] for y in y_train], marker='o', color='lightblue', linestyle='None')\n",
    "        plt.plot([xv[0] for xv in X_valid], [y[0] for y in y_valid], marker='o', color='pink', linestyle='None')\n",
    "    plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.2),\n",
    "              ncol=3, fancybox=True, shadow=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913addb-2e48-4cd7-b635-b17fd578b58b",
   "metadata": {},
   "source": [
    "### Generate TS with options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52406494-8935-4eb1-bf47-929a85626c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select a target class and its parameters (see: utils.py), e.g.\n",
    "#   Target_sin() # Target_2_sins() # Target_poly() # Target_poly_3()\n",
    "#   Target_line() # Target_line(slope=0.5, intercept=0.2, xmin=0, xmax=1.5)\n",
    "#   Target_trig_trend() # Target_jitter()\n",
    "#   Target_beer() # Target_beer(pt_from=104, pt_to=156)\n",
    "\n",
    "fun_train = Target_beer(pt_from=104, pt_to=156) # Target_2_sins() # Target_poly_3()\n",
    "sel_wind = 3\n",
    "\n",
    "X_train_org, y_train_org, X_valid_org, y_valid_org = \\\n",
    "    gen_ts_windows(fun_train, samples_hi_res, split, wind_size, wind_step, differencing=False)\n",
    "\n",
    "X_train_org_noisy, y_train_org_noisy, X_valid_org_noisy, y_valid_org_noisy = \\\n",
    "    gen_ts_windows(fun_train, samples_hi_res, split, wind_size, wind_step, differencing=False, noise=noise_org)\n",
    "\n",
    "# fun_train = Target_2_sins()\n",
    "X_train_ts, y_train_ts, X_valid_ts, y_valid_ts = \\\n",
    "    gen_ts_windows(fun_train, samples_hi_res, split, wind_size, wind_step, differencing=True)\n",
    "\n",
    "X_train_noisy, y_train_noisy, X_valid_noisy, y_valid_noisy = \\\n",
    "    gen_ts_windows(fun_train, samples_hi_res, split, wind_size, wind_step, differencing=True, noise=noise_ts)\n",
    "\n",
    "### Plot all TSs\n",
    "qae_plot_source_data(X_train_org, y_train_org, X_valid_org, y_valid_org, sel_wind=sel_wind, add_markers=False,\n",
    "                    title='Original time series', ylabel='Target value')\n",
    "qae_plot_source_data(X_train_org_noisy, y_train_org_noisy, X_valid_org_noisy, y_valid_org_noisy, sel_wind=sel_wind, add_markers=False,\n",
    "                    title=f'Original time series with noise ({noise_org})', ylabel='Target value')\n",
    "# qae_plot_source_data(X_train_ts, y_train_ts, X_valid_ts, y_valid_ts, sel_wind=100, add_markers=False,\n",
    "#                     title=f'Differenced pure time series')\n",
    "# qae_plot_source_data(X_train_noisy, y_train_noisy, X_valid_noisy, y_valid_noisy, sel_wind=100, add_markers=False,\n",
    "#                     title=f'Differenced time series with noise ({noise_ts})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e1a47-6715-4d00-be3f-ef5ad9a81c9d",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7872e2f-b262-4551-97cf-b54be456ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from qiskit import ClassicalRegister, QuantumRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.visualization import plot_histogram, plot_bloch_vector, plot_state_city, plot_state_paulivec\n",
    "from qiskit import Aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2107c5-c728-4d76-8893-4a8d2c69b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts measurements amplitudes a and b in a|0>+b|1> into bloch vector\n",
    "def convert_amps_to_xyz(a, b):\n",
    "    x = 2*np.real(a*np.conjugate(b))\n",
    "    y = 2*np.imag(b*np.conjugate(a))\n",
    "    z = a*np.conjugate(a)-b*np.conjugate(b)\n",
    "    return [x, y, z] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847860fb-9725-49f9-a80b-f222a15f2873",
   "metadata": {},
   "source": [
    "### Angle encoding\n",
    "Deltas between consecutive time series values have been angle encoded. In the context of a quibit representation (see the Figure), the encoding assumes zero to be encoded as H state, negative values to be rotations up, while positive values as rotations down. This encoding allows cumulative sequence calculations and easy value decoding upong the qubit measurements. Should there be huge voilatility in data, additional scaling has been added to shrink the region of valid angular qubit positions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac123bb3-e9eb-48fd-95f7-56c47c5d62b8",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <!--img src=\"attachment:qae_fig2_wide.png\" width=\"1000\"-->\n",
    "    <img src=\"../images/seq-value-encoding.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "**Figure: Sequence value coding as qubit angular rotations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61130d8f-04e3-4da1-a166-6fb798eb6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Angle encoding of a TS value relative to the previous value\n",
    "#   val: value in [-1..+1] range to be encoded\n",
    "#   optional scaler=np.pi/2: Number scaler \n",
    "#   optional err_range=0/0.05: allows range scaling to cater for accumulating errors\n",
    "#   returns: Encoding of the next value relative to the previous value\n",
    "def ts_relang_encode_val(val, scaler=np.pi/2, err_range=0):\n",
    "    return val * scaler * (1 - 2 * err_range)\n",
    "\n",
    "### Decoding\n",
    "def ts_relang_decode_val(val, scaler=np.pi/2, err_range=0):\n",
    "    return val / (scaler * (1 - 2 * err_range))\n",
    "\n",
    "### Normalises the value to 1 (not required with angle encoding)\n",
    "def ts_relang_norm_val(next_code):\n",
    "    norm_code = next_code\n",
    "    return norm_code\n",
    "\n",
    "### Print encoding and decoding for testing\n",
    "def print_ts_relang_encode_val(n):\n",
    "    val = round(ts_relang_encode_val(n), 3)\n",
    "    if val == 0:\n",
    "        print(f'{(n)} -> {val} (π*{0.0})')\n",
    "    else:\n",
    "        print(f'{(n)} -> {val} (π/{round(np.pi / val, 3)})')\n",
    "    \n",
    "def print_ts_relang_decode_val(n):\n",
    "    if n == 0:\n",
    "        print(f'{round(n, 3)} (π*{0.0}) -> {ts_relang_decode_val(n)}')\n",
    "    else:\n",
    "        print(f'{round(n, 3)} (π/{round(np.pi / n, 3)}) -> {round(ts_relang_decode_val(n), 3)}')\n",
    "\n",
    "def print_ts_relang_norm_val(p):\n",
    "    print(f'{round(p, 3)} -> {round(ts_relang_norm_val(p), 3)}')\n",
    "\n",
    "### Test\n",
    "# print('Encoding:')\n",
    "# print_ts_relang_encode_val(0)\n",
    "# print_ts_relang_encode_val(0.5)\n",
    "# print_ts_relang_encode_val(0.7)\n",
    "# print_ts_relang_encode_val(0.25)\n",
    "# print_ts_relang_encode_val(1.2) # Out of [0..pi] range\n",
    "# print_ts_relang_encode_val(-0.7) # Out of [0..pi] range\n",
    "\n",
    "# print('\\nDecoding:')\n",
    "# print_ts_relang_decode_val(np.pi)\n",
    "# print_ts_relang_decode_val(0*np.pi)\n",
    "# print_ts_relang_decode_val(np.pi/4)\n",
    "# print_ts_relang_decode_val(-np.pi/2)\n",
    "# print_ts_relang_decode_val(np.pi/8)\n",
    "# print_ts_relang_decode_val(-0.9*np.pi) # Out of [0..pi] range\n",
    "\n",
    "# print('\\nNormalise Encoding:')\n",
    "# print_ts_relang_norm_val(1.5*np.pi)\n",
    "# print_ts_relang_norm_val(-0.5*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07cfc0-9930-43bb-8d63-27b41fd9eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoding the entire data set\n",
    "def ts_relang_encode(wind_set, scaler=np.pi):\n",
    "    encoded_set = []\n",
    "    for wind_idx in range(wind_set.shape[0]):\n",
    "        wind = wind_set[wind_idx]\n",
    "        encoded_wind = []\n",
    "        for val_idx in range(wind.shape[0]):\n",
    "            val = wind[val_idx]\n",
    "            encoded_val = ts_relang_encode_val(val, scaler)\n",
    "            encoded_wind.append(encoded_val)\n",
    "        encoded_set.append(encoded_wind)\n",
    "    org_wind_start = np.array([w[0] for w in wind_set])\n",
    "    return np.array(encoded_set), org_wind_start\n",
    "\n",
    "### Encoding the entire data set\n",
    "def ts_relang_decode(org_wind_start, encoded_wind_set, scaler=np.pi):\n",
    "    decoded_set = []\n",
    "    for wind_idx in range(encoded_wind_set.shape[0]):\n",
    "        wind = encoded_wind_set[wind_idx]\n",
    "        decoded_wind = []\n",
    "        for val_idx in range(wind.shape[0]):\n",
    "            encoded_val = wind[val_idx]\n",
    "            decoded_val = ts_relang_decode_val(encoded_val, scaler)\n",
    "            decoded_wind.append(decoded_val)\n",
    "            prev = decoded_val\n",
    "        decoded_set.append(decoded_wind)\n",
    "    return np.array(decoded_set)\n",
    "\n",
    "### In agle encoding, encoded data is already normalised\n",
    "def ts_relang_norm(encoded_wind_set):\n",
    "    return np.array(encoded_wind_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06583094-df0f-40ca-8751-8560d99473b4",
   "metadata": {},
   "source": [
    "### Preparing data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274dbfdd-1096-4ecb-9cf9-4dd66440b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoding of TS windows which are \n",
    "y_train_enc, org_train_start = ts_relang_encode(y_train_ts)\n",
    "y_valid_enc, org_valid_start = ts_relang_encode(y_valid_ts)\n",
    "\n",
    "y_train_noisy_enc, org_train_noisy_start = ts_relang_encode(y_train_noisy) \n",
    "y_valid_noisy_enc, org_valid_noisy_start = ts_relang_encode(y_valid_noisy)\n",
    "\n",
    "### Testing validation windows\n",
    "\n",
    "# y_train_dec = ts_relang_decode(org_train_start, ts_relang_norm(y_train_enc))\n",
    "# print('\\nTraining windows before encoding:\\n', y_train_ts[5:8])\n",
    "# print('\\nTraining windows after encoding:\\n', y_train_enc[5:8])\n",
    "# print('\\nTraining windows org start:\\n', org_train_start[5:8])\n",
    "# print('\\nTraining windows after decoding:\\n', y_train_dec[5:8])\n",
    "\n",
    "# y_valid_dec = ts_relang_decode(org_valid_start, y_valid_enc)\n",
    "# print('\\nValidation windows before encoding:\\n', y_valid_ts[0:8])\n",
    "# print('\\nValidation windows after encoding:\\n', y_valid_enc[0:8])\n",
    "# print('\\nValidation windows org start:\\n', org_valid_start[0:8])\n",
    "# print('\\nValidation windows after decoding:\\n', y_valid_dec[0:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d69185-1f12-4375-9b14-78b14a240fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot deltas in the time series\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.title(f\"Differenced Training Data (noise={noise_ts} added to original data)\")\n",
    "plt.xlabel(\"Range (only 1st sliding window elements)\")\n",
    "plt.ylabel(\"Target value (deltas)\")\n",
    "\n",
    "sel_range=range(len(y_train_enc))\n",
    "#sel_range=range(70, 100, 1)\n",
    "#sel_range=range(10, 40, 1)\n",
    "\n",
    "plt.plot(list(sel_range), [y[0] for y in y_train_enc[sel_range]], color='blue', label='Training data (pure)')\n",
    "plt.plot(list(sel_range), [y[0] for y in y_train_noisy_enc[sel_range]], color='red', label='Training data (with noise)')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.2),\n",
    "          ncol=2, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2b65f-d75f-428e-a0dc-19bbe8c0520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot deltas in the time series\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.title(f\"Differenced Testing Data (noise={noise_ts} added to original data)\")\n",
    "plt.xlabel(\"Range (only 1st sliding window elements)\")\n",
    "plt.ylabel(\"Target value (deltas)\")\n",
    "\n",
    "sel_range=range(len(y_valid_enc))\n",
    "#sel_range=range(70, 100, 1)\n",
    "#sel_range=range(10, 40, 1)\n",
    "\n",
    "plt.plot(list(sel_range), [y[0] for y in y_valid_enc[sel_range]], color='blue', label='Testing data (pure)')\n",
    "plt.plot(list(sel_range), [y[0] for y in y_valid_noisy_enc[sel_range]], color='red', label='Testing data (with noise)')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.2),\n",
    "          ncol=2, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24563883",
   "metadata": {},
   "source": [
    "## Building and training a Quantum Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Libraries used in QAE development\n",
    "\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from qiskit import ClassicalRegister, QuantumRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_algorithms.optimizers import COBYLA, NELDER_MEAD, SPSA\n",
    "from qiskit.circuit.library import RealAmplitudes, TwoLocal, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit.visualization import plot_histogram, plot_state_city, plot_state_paulivec\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit.circuit import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64eeab4-5b0f-4ceb-9edf-5bac81bf728e",
   "metadata": {},
   "source": [
    "### Sequence encoder\n",
    "The sequence is encoded as a series of angle rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d7e02-2072-4dfa-b5db-bb6d6db45df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates a circuit encoding a sequence \n",
    "#   - Adds H gates to position each qubit at a \"zero\" position\n",
    "#   - Each sequence value y-rotates the qubit state either up (negative) or down (positive)\n",
    "#   - Use only as many input values as the number of qubits, if not enough provided zero rotations are added\n",
    "#\n",
    "#   qubits_no: Number of qubits\n",
    "#   input_no: Number of values in a sequence\n",
    "#   optional classreg=False: Flag indicating if a classical register is to be added\n",
    "#   optional meas_q=None: Indicates the qubit to be measured, active only when classreg=True\n",
    "#   err_added: Indicates percent of error to be generated\n",
    "#   returns: Circuit encoding a sequence\n",
    "def sequence_encoder(qubit_no, input_no=None, classreg=False, meas_q=None, label='S'):\n",
    "\n",
    "    if input_no == None: \n",
    "        input_no = qubit_no\n",
    "    used_sgates = 0\n",
    "\n",
    "    qr = QuantumRegister(qubit_no, 'q')\n",
    "    cr = ClassicalRegister(1, 'meas')\n",
    "    if classreg:\n",
    "        seq = QuantumCircuit(qr, cr, name='sequence')\n",
    "    else:\n",
    "        seq = QuantumCircuit(qr, name='sequence')\n",
    "\n",
    "    # Data-encoding circuit block, packs different input vars\n",
    "    for q in range(qubit_no):\n",
    "        seq.h(q)\n",
    "        if q > input_no:\n",
    "            seq.ry(0, q)\n",
    "        else:\n",
    "            param_x = Parameter(label+'('+str(used_sgates)+')') if used_sgates < input_no else 0\n",
    "            seq.ry(param_x, q)\n",
    "        used_sgates += 1\n",
    "\n",
    "    if classreg and meas_q != None:\n",
    "        seq.measure(meas_q, 0)\n",
    "\n",
    "    return seq, seq.parameters[:]\n",
    "\n",
    "### Test a sample sequence encoder\n",
    "sample_seq, inp_params = sequence_encoder(7, 6, classreg=True, meas_q=2, label='In')\n",
    "print('\\n')\n",
    "display(sample_seq.draw(output='latex', style=\"iqp\", fold=False, scale=0.7))\n",
    "print('\\nInput parameters for the sequence: ', inp_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f7b35-61aa-4a4e-bf7a-95e78d3ea079",
   "metadata": {},
   "source": [
    "**Figure: Example of encoding for a sample sequence window**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793bc10",
   "metadata": {},
   "source": [
    "### Creation of an ansatz\n",
    "\n",
    "The selectede ansatz is the Qiskit RealAmplitude ansatz (2-local circuit) - the prepared quantum states will only have real amplitudes, and does not rely on full connectivity between qubits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78152563",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates an ansatz to be used for QAE Encoder/Decoder\n",
    "#   num_latent: size of the latent area\n",
    "#   num_trash: size of the trash area\n",
    "#   reps: number of repeating layers\n",
    "#   ent: type of entanglement layer (linear, reverse_linear, full, circular, sca, pairwise)\n",
    "\n",
    "# Standard ansatz based Ry and Cx\n",
    "def ansatz(num_qubits, reps=3, ent='sca', insert_barriers=False, label='A'):\n",
    "    anz = RealAmplitudes(num_qubits, reps=reps, entanglement=ent, insert_barriers=insert_barriers,\n",
    "                        parameter_prefix=label)\n",
    "    return anz\n",
    "\n",
    "### Test the selected ansatz\n",
    "sample_ansatz = ansatz(7, reps=2, ent='sca', insert_barriers=True) # linear, reverse_linear, full, circular, sca\n",
    "print('\\n')\n",
    "display(sample_ansatz.decompose().draw(\"latex\", style=\"iqp\", scale=0.7, fold=False))\n",
    "print(f'\\nNumber of ansatz parameters: {len(sample_ansatz.parameters)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd26f959-e021-4d13-94b0-72e6a069288e",
   "metadata": {},
   "source": [
    "**Figure: Sample QAE ansatz**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8925b02",
   "metadata": {},
   "source": [
    "### Swap Test\n",
    "For two qubts, it returns a squared inner product between their states. In this implementation, it estimates the overlap between the states of all participating qubits. \n",
    "The repeated measurement of 1 indicates that the quantum states are identical. For two qubits, if the measurement returns 0.5 then the two states are orthogonal.\n",
    "However, orthogonality of the remaining states is no longer possible, so the measurements will be further away from 1, possibly confusing the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8fcae-9320-451b-a0b6-42124e00b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Swap test circuit\n",
    "def swap_test(num_trash):\n",
    "    qr = QuantumRegister(2 * num_trash + 1, \"swap\")\n",
    "    cr = ClassicalRegister(1, \"c\")\n",
    "    swap_qc = QuantumCircuit(qr, cr)\n",
    "    auxiliary_qubit = 2 * num_trash\n",
    "    \n",
    "    swap_qc.h(auxiliary_qubit)\n",
    "    for i in range(num_trash):\n",
    "        swap_qc.cswap(auxiliary_qubit, i, num_trash + i)    \n",
    "    swap_qc.h(auxiliary_qubit)\n",
    "    swap_qc.measure(auxiliary_qubit, cr[0])\n",
    "    return swap_qc\n",
    "\n",
    "### Test a swap test circuit\n",
    "sample_swap_qc = swap_test(2)\n",
    "print(f'\\nExample swap test circuit: {len(sample_swap_qc.qubits)}\\n')\n",
    "display(sample_swap_qc.draw(\"latex\", style=\"iqp\", scale=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22acea2d-5847-4453-a1b7-8f990dfcba5f",
   "metadata": {},
   "source": [
    "### Training Half-QAE Encoder: Input + Encoder + Swap Test\n",
    "It determines the states of all trash qubits to be $\\lvert 0 \\rangle$ via a swap test, which returns 1 when they are all identical, and equal distribution of expectation values, when they are highly dissimilar. This is the most reliable assessment of state similarity, however, it is slow and duplicates the number of qubits in a circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0abd3-002b-4cc3-9759-6b7f27960272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder_with_swap_test(num_latent, num_trash, reps=4, ent='circular',\n",
    "                  seq_name='Input', seq_label='N', \n",
    "                  anz_name='Encoder', anz_label='X'):\n",
    "    qr = QuantumRegister(num_latent + 2 * num_trash + 1, \"q\")\n",
    "    cr = ClassicalRegister(1, \"c\")\n",
    "    fm_qc, _ = sequence_encoder(num_latent+num_trash, label=seq_label)\n",
    "    fm_qc.name = seq_name\n",
    "    anz_qc = ansatz(num_latent+num_trash, reps=reps, ent=ent, label=anz_label).decompose()\n",
    "    anz_qc.name = anz_name\n",
    "    swap_qc = swap_test(num_trash)\n",
    "    swap_qc.name = 'Swap'\n",
    "    \n",
    "    qc = QuantumCircuit(qr, cr)\n",
    "    qc.append(fm_qc, qargs=range(num_latent+num_trash))\n",
    "    qc.barrier()\n",
    "    qc.append(anz_qc, qargs=range(num_latent+num_trash))\n",
    "    qc.barrier()\n",
    "    qc.append(swap_qc, qargs=range(num_latent, num_latent + 2*num_trash+1), cargs=[0])\n",
    "    qc.barrier()\n",
    "\n",
    "    return qc, fm_qc.parameters, anz_qc.parameters\n",
    "\n",
    "### Test an encoder circuit\n",
    "sample_lat=5; sample_trash=2\n",
    "sample_aec, sample_fm_parameters, sample_anz_parameters = \\\n",
    "    train_encoder_with_swap_test(sample_lat, sample_trash, reps=2, ent='sca', seq_label='S', seq_name='Sequence')\n",
    "\n",
    "# print(f'\\nExample autoencoder circuit (with {sample_lat} latent and {sample_trash} trash qubits):')\n",
    "# print(f'\\nEncoder parameters:\\n{sample_anz_parameters}')\n",
    "# print(f'\\nIn/Out  parameters:\\n{sample_fm_parameters}\\n\\n')\n",
    "\n",
    "display(sample_aec.decompose().draw(\"latex\", style=\"iqp\", scale=1, cregbundle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90235400-e60b-4853-bdb3-b3c35eb8321f",
   "metadata": {},
   "source": [
    "**Figure: Half-QAE structure for training using only Encoder and the Swap Test**<br/>\n",
    "The swap test compares the states of qubits in the trash space with qubits initialised with $\\lvert 0 \\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f1582-db66-46b0-9879-6d3da8294b7f",
   "metadata": {},
   "source": [
    "### Training Half-QAE Encoder: Input + Encoder without a Swap Test\n",
    "It assesses the state of all trash qubits to be $\\lvert 0 \\rangle$ by their direct measurement and estimating the probability $P(\\lvert 0 \\rangle)^n$ (where $n$ is the number of qubits in the trash space. This approach to measuring qubit similarity is not as nuanced as what's is provided by swap test, as we miss on the state proximity determined by their inner product. However, the measurement is fast(er) and does not need additional qubits. The circuit training needs the cost function $cost = P(1-\\lvert 0 \\rangle)^n$, which needs to be minimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6762135-de4e-43a2-951d-3282baa9c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building partial QAE for its training without a swap test\n",
    "\n",
    "def train_encoder(num_latent, num_trash, reps=4, ent='circular',\n",
    "                  seq_name='Input', seq_label='N', \n",
    "                  anz_name='Encoder', anz_label='X'):\n",
    "    qr = QuantumRegister(num_latent + num_trash, \"q\")\n",
    "    cr = ClassicalRegister(num_trash, \"c\")\n",
    "    fm_qc, _ = sequence_encoder(num_latent+num_trash, label=seq_label)\n",
    "    fm_qc.name = seq_name\n",
    "    anz_qc = ansatz(num_latent+num_trash, reps=reps, ent=ent, label=anz_label).decompose()\n",
    "    anz_qc.name = anz_name\n",
    "\n",
    "    \n",
    "    circuit = QuantumCircuit(qr, cr)\n",
    "\n",
    "    ### Sequence\n",
    "    circuit.append(fm_qc, qargs=range(num_latent+num_trash))\n",
    "\n",
    "    ### Encoder\n",
    "    circuit.barrier()\n",
    "    circuit.append(anz_qc, qargs=range(num_latent + num_trash))\n",
    "    \n",
    "    ### Measurements\n",
    "    circuit.barrier()\n",
    "    for i in range(num_trash):\n",
    "        circuit.measure(qr[num_latent+i], cr[i])\n",
    "    \n",
    "    return circuit, fm_qc, anz_qc\n",
    "\n",
    "### Test a training circuit\n",
    "sample_ae, _, _ = train_encoder(5, 2, reps=2, ent='sca')\n",
    "print('\\nExample autoencoder circuit:\\n')\n",
    "display(sample_ae.draw(\"latex\", style=\"iqp\", scale=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1ae8c-cb13-4242-8faf-441c156b6d8c",
   "metadata": {},
   "source": [
    "**Figure: Half-QAE structure for training using only Encoder and measurements of qubit states**<br/>\n",
    "The $\\lvert 0 \\rangle$ state of trash qubits is determined by the cost function: $cost = 1-P(\\lvert 0 \\rangle^n)$ (with n - number of qubits in trash space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ee727-fe85-42b4-8ec9-5e977f31c57b",
   "metadata": {},
   "source": [
    "### Training Full-Circuit: Input + Encoder + Decoder + Output + Swap Test\n",
    "*Note: Position of the output block may vary<br/>Note: Decoder could be an inverse of encoder or become an independent block*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b759a8-4b41-4cff-bb28-bba5109e9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qae(num_latent, num_trash, reps=4, ent='sca',\n",
    "              in_seq_name='Input', in_seq_label='I', \n",
    "              out_seq_name='Output', out_seq_label='O', \n",
    "              enc_name='Encoder', enc_label='X',\n",
    "              dec_name='Decoder', dec_label='Y',\n",
    "              keep_encoder=False):\n",
    "\n",
    "    ### Create a circuit and its components\n",
    "    lt_qubits = num_latent+num_trash\n",
    "    qr = QuantumRegister(lt_qubits, \"q\")\n",
    "    cr = ClassicalRegister(lt_qubits, \"c\")\n",
    "    in_qc, _ = sequence_encoder(lt_qubits, label=in_seq_label)\n",
    "    in_qc.name = in_seq_name\n",
    "    out_qc, _ = sequence_encoder(lt_qubits, label=out_seq_label)\n",
    "    out_qc.name = out_seq_name\n",
    "    enc_qc = ansatz(lt_qubits, reps=reps, ent=ent, label=enc_label).decompose()\n",
    "    enc_qc.name = enc_name\n",
    "    dec_qc = ansatz(lt_qubits, reps=reps, ent=ent, label=dec_label).decompose()\n",
    "    dec_qc.name = dec_name\n",
    "\n",
    "    ### Input\n",
    "    qc = QuantumCircuit(qr, cr)\n",
    "    qc.append(in_qc, qargs=range(lt_qubits))\n",
    "\n",
    "    ### Encoder\n",
    "    qc.barrier()\n",
    "    qc.append(enc_qc, qargs=range(lt_qubits))\n",
    "\n",
    "    ### Latent / Trash\n",
    "    qc.barrier()\n",
    "    for i in range(num_trash):\n",
    "        qc.reset(num_latent + i)\n",
    "\n",
    "    ### Decoder\n",
    "    qc.barrier()\n",
    "    if keep_encoder:\n",
    "        dec_inv_qc = enc_qc.inverse()\n",
    "    else:\n",
    "        dec_inv_qc = dec_qc.inverse()\n",
    "    qc.append(dec_inv_qc, qargs=range(lt_qubits))\n",
    "\n",
    "    ### Inverted output (trans input)\n",
    "    qc.barrier()\n",
    "    out_inv_qc = out_qc.inverse()\n",
    "    qc.append(out_inv_qc, qargs=range(lt_qubits))\n",
    "\n",
    "    ### Measurements\n",
    "    qc.barrier()\n",
    "    for i in range(len(qc.qubits)):\n",
    "        qc.measure(qr[i], cr[i])\n",
    "    \n",
    "    ### Collect weight parameters\n",
    "    train_weight_params = []\n",
    "    for enc_p in enc_qc.parameters:\n",
    "        train_weight_params.append(enc_p)    \n",
    "    if not keep_encoder:\n",
    "        for dec_p in dec_qc.parameters:\n",
    "            train_weight_params.append(dec_p)\n",
    "\n",
    "    ### Collect in/out parameters\n",
    "    in_out_params = []\n",
    "    for in_p in in_qc.parameters:\n",
    "        in_out_params.append(in_p)    \n",
    "    for out_p in out_qc.parameters:\n",
    "        in_out_params.append(out_p)        \n",
    "    \n",
    "    if keep_encoder:\n",
    "        return qc, in_out_params, enc_qc.parameters, enc_qc.parameters, train_weight_params\n",
    "    else:\n",
    "        return qc, in_out_params, enc_qc.parameters, dec_qc.parameters, train_weight_params\n",
    "\n",
    "### Test an encoder circuit\n",
    "sample_tqae, in_out_params, enc_params, dec_params, all_weight_params = \\\n",
    "    train_qae(5, 2, reps=2, ent='sca', in_seq_label='N', in_seq_name='Noisy Input', keep_encoder=False)\n",
    "print('\\nExample autoencoder circuit'+\n",
    "      '\\nNote: Decoder is either an inverse of the encoder or an independent decoder block):')\n",
    "\n",
    "# print(f'\\nIn/Out  parameters:\\n{in_out_params}')\n",
    "# print(f'\\nEncoder parameters:\\n{enc_params}')\n",
    "# print(f'\\nDecoder parameters:\\n{dec_params}')\n",
    "# print(f'\\nWeight parameters:\\n{all_weight_params}\\n\\n')\n",
    "\n",
    "# display(sample_tqae.decompose().draw(\"latex\", style=\"iqp\", scale=0.8, cregbundle=False))\n",
    "display(sample_tqae.draw(\"latex\", style=\"iqp\", scale=0.8, fold=-1)) # latex, mpl, \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b810f-c9e5-4c87-9b8a-1d7bf2144b07",
   "metadata": {},
   "source": [
    "**Figure: Full-QAE structure for training (using Encoder+Decoder and a Swap Test)**<br/>\n",
    "*The swap test is performed on all input/output qubits to determine the value of our cost function.<br/><br/>\n",
    "Note: Position of the output block may vary<br/>Note: Decoder could be an inverse of encoder or become an independent block*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d4d1d-5952-4e01-85ca-21d8f936b02e",
   "metadata": {},
   "source": [
    "### Testing Circuit - The entire QAE\n",
    "\n",
    "The full Autoencoder consists of both the Encoder and Decoder, which is simply an inverted Encoder. \n",
    "Both the Encoder and Decoder can be initialised using the same parameters obtained from the Encoder (plus swap test) training.\n",
    "By applying the full QAE circuit to a test dataset, we can then determine the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e38b86-8191-4876-8dfe-82c324d1cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full QAE for testing the previously trained model\n",
    "\n",
    "def qae(lat_no, trash_no, reps=2, ent='sca', classreg=False, meas_q=None, keep_encoder=False,\n",
    "          in_seq_name='Input', in_seq_label='I', \n",
    "          enc_name='Encoder', enc_label='X',\n",
    "          dec_name='Decoder', dec_label='Y'):\n",
    "\n",
    "    # Prepare a circuit\n",
    "    qr = QuantumRegister(lat_no + trash_no, 'q')\n",
    "    cr = ClassicalRegister(1, 'meas')\n",
    "    # qae_qc = QuantumCircuit(lat_no + trash_no, 1)\n",
    "    if classreg:\n",
    "        qae_qc = QuantumCircuit(qr, cr, name='qae')\n",
    "    else:\n",
    "        qae_qc = QuantumCircuit(qr, name='qae')\n",
    "\n",
    "    # Create all QAE components\n",
    "    in_qc, _ = sequence_encoder(lat_no + trash_no, label=in_seq_label)\n",
    "    in_qc.name = in_seq_name\n",
    "    enc_qc = ansatz(lat_no+trash_no, reps=reps, ent=ent, label=enc_label)\n",
    "    enc_qc.name = enc_name\n",
    "    dec_qc = ansatz(lat_no+trash_no, reps=reps, ent=ent, label=dec_label)\n",
    "    dec_qc.name = dec_name\n",
    "\n",
    "    # Create a circuit\n",
    "    qae_qc.append(in_qc, qargs=range(lat_no + trash_no))\n",
    "    qae_qc.barrier()\n",
    "    qae_qc.append(enc_qc, qargs=range(lat_no + trash_no))\n",
    "    qae_qc.barrier()\n",
    "    \n",
    "    for i in range(trash_no):\n",
    "        qae_qc.reset(lat_no + i)\n",
    "    \n",
    "    qae_qc.barrier()\n",
    "    if keep_encoder:\n",
    "        dec_inv_qc = enc_qc.inverse()\n",
    "    else:\n",
    "        dec_inv_qc = dec_qc.inverse()\n",
    "    qae_qc.append(dec_inv_qc, qargs=range(lat_no + trash_no))\n",
    "\n",
    "    # Add optional measurement\n",
    "    if classreg and meas_q != None:\n",
    "        qae_qc.barrier()\n",
    "        qae_qc.measure(meas_q, 0)\n",
    "\n",
    "    return qae_qc, in_qc, enc_qc, dec_qc\n",
    "\n",
    "sample_qae_qc, sample_in_qc, sample_enc_qc, sample_dec_qc = qae(5, 2, reps=2, ent='sca', classreg=True, meas_q=2, keep_encoder=False)\n",
    "\n",
    "### Show a sample test circuit - the sequence feature map and the ansatz will beused further\n",
    "print()\n",
    "print('\\n#QAE Input Parameters:', len(sample_in_qc.parameters))\n",
    "print('#Encoder/Decoder Weights:', len(sample_enc_qc.parameters)+len(sample_dec_qc.parameters))\n",
    "print('#QAE Total Weights:', len(sample_qae_qc.parameters))\n",
    "print('\\n')\n",
    "\n",
    "display(sample_qae_qc.draw(\"latex\", style=\"iqp\", scale=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916c1f8-d73a-4346-910c-5650a8c1beab",
   "metadata": {},
   "source": [
    "**Figure: Full QAE capable of mapping input sequence to its output (after Encoder/Decoder training)**\n",
    "\n",
    "*Note: Decoder could be an inverse of encoder or become an independent block*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242bb9e-eb79-4940-97ec-9f3bf96d3a71",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee78dd-3954-4e32-aae6-98ed37082916",
   "metadata": {},
   "source": [
    "**Sampler** needs to be imported from *qiskit_aer.primitives*.\n",
    "Unfortunately, *qiskit-aer-gpu 0.12.2* has a bug, which has been fixed \n",
    "in the next version *qiskit-aer-gpu 0.13.0*, see notes in the version table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2565f-2ddf-429d-b822-2a201f9802c3",
   "metadata": {},
   "source": [
    "### Simulator device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f9d6c-15fb-4804-9ff7-ae392440e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find what devices are available\n",
    "from qiskit_aer.backends import AerSimulator\n",
    "devices = AerSimulator().available_devices()\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1db286-09df-4111-9828-100e1bf8279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Force the CPU\n",
    "# devices = ('CPU')\n",
    "# devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9f653-63dc-4ac2-b235-0609010f2e59",
   "metadata": {},
   "source": [
    "### Sampler options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99ca57-6dfa-4fb6-8e4b-0ab6e55e2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a sampler suitable for the device\n",
    "#   GPU methods: statevector, tensor_network, density_matrix, unitary\n",
    "\n",
    "from qiskit.primitives import Sampler # For \"CPU\", ignores device=\"GPU\" option\n",
    "from qiskit_aer.primitives import Sampler as AerSampler # For device=\"GPU\" option\n",
    "\n",
    "seed = 2023\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "# Use GPU when present, otherwise CPU\n",
    "if 'GPU' in devices:\n",
    "    device = 'GPU'\n",
    "    sampler = AerSampler(\n",
    "        backend_options={'seed_simulator': seed, 'method': 'statevector', \n",
    "                         'device' : device, 'cuStateVec_enable' : True},\n",
    "        run_options={'seed': seed, 'shots': 1000},\n",
    "        transpile_options={\"seed_transpiler\": seed},\n",
    "    )\n",
    "else:\n",
    "    device = 'CPU'\n",
    "    sampler = Sampler()\n",
    "    sampler.set_options(method='statevector')\n",
    "    sampler.set_options(device=device)\n",
    "    sampler.set_options(seed=seed)\n",
    "    sampler.options\n",
    "\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0826169-5f52-4b0c-a994-b8719d09f8a9",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d355d-664d-4269-a59d-c5896e7e2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Various metrics calculated between two TS window sets given as dictionaries\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "### Merge a window set given as a dictionary into a list of its entries\n",
    "def merged_tswind(wind_dict, trim_left=0, trim_right=0):    \n",
    "    wind_list = []\n",
    "    sorted_keys = sorted(wind_dict.keys())\n",
    "    if (trim_left+trim_right) <= len(wind_dict[sorted_keys[0]]):\n",
    "        for sel_wind in sorted_keys:\n",
    "            wind = wind_dict[sel_wind]\n",
    "            wind = wind[trim_left:]\n",
    "            wind = wind[:-trim_right] if trim_right>0 else wind\n",
    "            wind_list.extend(wind)\n",
    "    return wind_list\n",
    "\n",
    "### Perform RMS on dictionaries\n",
    "def rms_tswin(wind_exp, wind_pred, trim_left=0, trim_right=0):\n",
    "    exp = merged_tswind(wind_exp, trim_left=trim_left, trim_right=trim_right)\n",
    "    pred = merged_tswind(wind_pred, trim_left=trim_left, trim_right=trim_right)\n",
    "    return np.sqrt(mean_squared_error(exp, pred))    \n",
    "\n",
    "### Perform MAE on dictionaries\n",
    "def mae_tswin(wind_exp, wind_pred, trim_left=0, trim_right=0):\n",
    "    exp = merged_tswind(wind_exp, trim_left=trim_left, trim_right=trim_right)\n",
    "    pred = merged_tswind(wind_pred, trim_left=trim_left, trim_right=trim_right)\n",
    "    return mean_absolute_error(exp, pred)    \n",
    "\n",
    "### Perform MAPE on dictionaries\n",
    "def mape_tswin(wind_exp, wind_pred, trim_left=0, trim_right=0):\n",
    "    exp = merged_tswind(wind_exp, trim_left=trim_left, trim_right=trim_right)\n",
    "    pred = merged_tswind(wind_pred, trim_left=trim_left, trim_right=trim_right)\n",
    "    return mean_absolute_percentage_error(exp, pred)    \n",
    "\n",
    "### Calculate R score on dictionaries\n",
    "def r2_tswin(wind_exp, wind_pred, trim_left=0, trim_right=0):\n",
    "    exp = merged_tswind(wind_exp, trim_left=trim_left, trim_right=trim_right)\n",
    "    pred = merged_tswind(wind_pred, trim_left=trim_left, trim_right=trim_right)\n",
    "    return r2_score(exp, pred)    \n",
    "\n",
    "### Sample data\n",
    "tsw_exp = {}\n",
    "tsw_exp[2] = [2, 5, 9, 20, 21]\n",
    "tsw_exp[5] = [5, 8, 9, 10, 11]\n",
    "tsw_exp[1] = [1, 2, 3, 4, 5]\n",
    "tsw_exp[3] = [3, 9, 11, 12, 13]\n",
    "\n",
    "tsw_pred = {}\n",
    "tsw_pred[2] = [3, 6, 10, 21, 20]\n",
    "tsw_pred[5] = [6, 9, 10, 11, 12]\n",
    "tsw_pred[1] = [2, 3, 4, 5, 4]\n",
    "tsw_pred[3] = [4, 10, 12, 13, 14]\n",
    "\n",
    "### Testing merge_tswind\n",
    "# print('\\nTesting merged_tswind')\n",
    "# print(f'\\tOriginal dict: {tsw_exp}')\n",
    "# print(f'\\tMerged dict: {merged_tswind(tsw_exp)}')\n",
    "# print(f'\\tMerged trim 2 left: {merged_tswind(tsw_exp, trim_left=2)}')\n",
    "# print(f'\\tMerged trim 1 right: {merged_tswind(tsw_exp, trim_right=1)}')\n",
    "# print(f'\\tMerged trim 2 left and 1 right: {merged_tswind(tsw_exp, trim_left=2, trim_right=1)}')\n",
    "# print(f'\\tMerged trim 3 left and 3 right: {merged_tswind(tsw_exp, trim_left=3, trim_right=3)}')\n",
    "# print()\n",
    "\n",
    "### Testing metrics\n",
    "# print('\\nTesting metrics')\n",
    "# print(f'\\tRMS: {rms_tswin(tsw_exp, tsw_pred)}')\n",
    "# print(f'\\tMAE: {mae_tswin(tsw_exp, tsw_pred)}')\n",
    "# print(f'\\tMAPE: {mape_tswin(tsw_exp, tsw_pred)}')\n",
    "# print(f'\\tR2: {r2_tswin(tsw_exp, tsw_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-second",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "We build our cost function, based on the swap test between the reference and trash space for the digit dataset. To do this, we again use Qiskit's CircuitQNN network and use the same interpret function as we are measuring the probability of getting the final qubit in the $|1\\rangle$ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle as data_shuffle\n",
    "default_backend = Aer.get_backend('aer_simulator_statevector')\n",
    "\n",
    "### Converts numbers to their binary representation\n",
    "def digit_list(a, n_bits):\n",
    "    return np.array([int(i) for i in f'{a:0{n_bits}b}'])\n",
    "\n",
    "### Calculates an inner join on binary representation\n",
    "def inner_join(a, b, n_bits):\n",
    "    inna = digit_list(a, n_bits)\n",
    "    innb = digit_list(b, n_bits)\n",
    "    return np.inner(inna, innb)\n",
    "\n",
    "### Makes an array indexed by number and \n",
    "#   returns the number of binary ones in its representation\n",
    "def make_1s_count(bin_digs):\n",
    "    dig_arr = [0]*bin_digs\n",
    "    for i in range(bin_digs):\n",
    "        dig_arr[i] = sum(digit_list(i, bin_digs))\n",
    "    return np.array(dig_arr)\n",
    "\n",
    "### Counts the probability of all measurements identical to zero\n",
    "def cost_swap(probs):\n",
    "    recs = probs.shape[0]\n",
    "    return np.sum(probs[:, 1]) / recs\n",
    "\n",
    "### Counts the probability of measurements which is not all zeros\n",
    "def cost_zero(probs):\n",
    "    recs = probs.shape[0]\n",
    "    return 1.0 - np.sum(probs[:, 0]) / recs\n",
    "\n",
    "### Counts the probability weighted number of 1s per record\n",
    "def cost_min1s(probs):\n",
    "    digit_no = int(np.log2(probs.shape[1]+1))\n",
    "    recs = probs.shape[0]\n",
    "    digits_wsum = 0\n",
    "    for rec in range(recs):\n",
    "        for i in range(digit_no):\n",
    "            digits_wsum += sum(digit_list(i, digit_no))*probs[rec, i]\n",
    "    return digits_wsum\n",
    "\n",
    "# make the plot nicer\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6) \n",
    "\n",
    "### Class Cost\n",
    "class Cost:\n",
    "    name = \"Cost class\"\n",
    "    \n",
    "    # Initialises the costs\n",
    "    def __init__(self, train_set, \n",
    "                 optimizer, init_vals, shuffle=False, shuffle_interv=10, \n",
    "                 cost_type='min1s', # cost_type = min1s, swap, zeroes\n",
    "                 yscale='linear', # yscale = linear, log / asinh, function, functionlog, logit, symlog\n",
    "                ):\n",
    "        self.shuffle = shuffle\n",
    "        self.shuffle_interv = shuffle_interv\n",
    "        self.objective_func_vals = []\n",
    "        self.opt = optimizer\n",
    "        self.init_vals = init_vals\n",
    "        self.iter = 0\n",
    "        self.rand = 2023\n",
    "        self.init_time = time.time()\n",
    "        self.elapsed_time = 0\n",
    "        self.cost_type = cost_type\n",
    "        self.yscale = yscale\n",
    "        self.perform_tests=False\n",
    "\n",
    "        if self.shuffle:\n",
    "            self.train_set = data_shuffle(train_set, random_state=self.rand)\n",
    "        else:\n",
    "            self.train_set = train_set\n",
    "\n",
    "    ### Set testing\n",
    "    def init_testing(self, valid_set, train_noisy_set, valid_noisy_set,\n",
    "                     num_latent=8, num_trash=2, reps=2, ent='sca', backend=default_backend, shots=10000\n",
    "                    ):\n",
    "        self.perform_tests=True\n",
    "        self.valid_set = valid_set\n",
    "        self.params = []\n",
    "        self.mae_train_vals = []\n",
    "        self.mae_valid_vals = []\n",
    "        self.num_latent=num_latent\n",
    "        self.num_trash=num_trash\n",
    "        self.reps=reps\n",
    "        self.ent=ent\n",
    "        self.backend=backend,\n",
    "        self.shots=shots\n",
    "    return\n",
    "        \n",
    "    ### Reset objective function values\n",
    "    def reset_objfuncs(self):\n",
    "        self.objective_func_vals = []\n",
    "        self.mae_train_vals = []\n",
    "        self.mae_valid_vals = []\n",
    "        self.params = []\n",
    "        self.elapsed_time = 0\n",
    "        self.init_time = time.time()\n",
    "\n",
    "    ### Plot cost\n",
    "    def cost_plot(self):\n",
    "        min_cost = min(self.objective_func_vals)\n",
    "        clear_output(wait=True)\n",
    "        plt.title(f'Cost function value against iteration (iter# {self.iter}, '+\n",
    "                  f'min cost={np.round(min_cost, 4)}, '+\n",
    "                  f'elapsed time={np.round(self.elapsed_time, 0)} secs)')\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Cost function value\")\n",
    "        plt.yscale(self.yscale)\n",
    "        plt.plot(range(len(self.objective_func_vals)), self.objective_func_vals)\n",
    "        plt.show()\n",
    "\n",
    "    ### Plot MAE\n",
    "    def cost_mae_plot(self):\n",
    "        # clear_output(wait=True)\n",
    "        plt.title(f'R2 against iteration (iter# {self.iter}, '+\n",
    "                  f'max R2={np.round(max_r2, 4)}, '+\n",
    "                  f'elapsed time={np.round(self.elapsed_time, 0)} secs)')\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"MAE\")\n",
    "        plt.yscale(self.yscale)\n",
    "        plt.plot(range(len(self.r2_train_vals)), self.r2_vals)\n",
    "        plt.show()\n",
    "\n",
    "    ### Circuit test\n",
    "    def test(self, sel_wind_set, winds_pure, winds_noise):\n",
    "        in_org_set = {}\n",
    "        out_reconstr_set = {}\n",
    "    \n",
    "        for wind_idx in range(len(sel_wind_set)):\n",
    "        \n",
    "            sel_wind = sel_wind_set[wind_idx]    \n",
    "            wind = winds_noise[sel_wind] # Use noisy window for manipulation            \n",
    "\n",
    "            ### Find the QAE resulting window state vector representation\n",
    "            out_meas = []\n",
    "            for meas_q in range(len(wind)):\n",
    "                last_params = self.params(len(self.params)-1)\n",
    "                param_values = np.concatenate((wind, last_params))       \n",
    "                out_qc, _, _, _ = qae(self.num_latent, self.num_trash, \n",
    "                                      reps=self.reps, ent=self.ent, \n",
    "                                      classreg=True, keep_encoder=False, meas_q=meas_q)     \n",
    "                out_qc = out_qc.assign_parameters(param_values)\n",
    "                out_qc = out_qc.decompose().decompose()\n",
    "                meas_angle = single_qubit_angle_meas(out_qc, self.backend, shots=self.shots)\n",
    "                out_meas.append(meas_angle)\n",
    "        \n",
    "            ### Add window results\n",
    "            in_org_set[sel_wind] = list(winds_pure[sel_wind]) # Add pure window for reference\n",
    "            out_reconstr_set[sel_wind] = out_meas\n",
    "\n",
    "        ### Calculate the MAE for the selected windows\n",
    "        mae_inorg_outrec = mae_tswin(in_org_set, out_reconstr_set, trim_left=0, trim_right=0)\n",
    "        \n",
    "    return mae_inorg_outrec\n",
    "\n",
    "    ### Cost function used in training\n",
    "    def cost_fun(self, params_values, *args):\n",
    "        self.iter = self.iter+1\n",
    "        \n",
    "        if (self.shuffle) and (self.iter % self.shuffle_interv == 0):\n",
    "            # print(f'*** Shuffled at iteration {self.iter}')\n",
    "            self.train_set = data_shuffle(self.train_set, random_state=self.rand)\n",
    "            \n",
    "        probs = qnn.forward(self.train_set, params_values)\n",
    "        if self.cost_type=='swap':\n",
    "            cost = np.sum(probs[:, 1]) / self.train_set.shape[0] # Checking for P(|0>) on inner product\n",
    "        elif self.cost_type == 'min1s':\n",
    "            cost = cost_min1s(probs)\n",
    "        else: # it is 'zeros'\n",
    "            cost = 1.0 - np.sum(probs[:, 0]) / self.train_set.shape[0] # Checking for P(|0>^n)\n",
    "        self.objective_func_vals.append(cost)\n",
    "        self.params.append(params_values)\n",
    "\n",
    "        ### Test the current model performance\n",
    "        train_mae = self.test(self.sel_train_wind_set, self.train_set, self.train_noisy_set)\n",
    "        self.mae_train_vals.append(train_mae)\n",
    "        valid_mae = self.test(self.sel_valid_wind_set, self.valid_set, self.valid_noisy_set)\n",
    "        self.mae_valid_vals.append(valid_mae)\n",
    "\n",
    "        self.elapsed_time = time.time() - self.init_time\n",
    "    \n",
    "        # plotting part\n",
    "        self.cost_plot()\n",
    "    \n",
    "        return cost\n",
    "\n",
    "    def optimize(self):\n",
    "        return opt.minimize(fun=self.cost_fun, x0=self.init_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eef2f6-9403-45c4-a3fa-1a59d4121b29",
   "metadata": {},
   "source": [
    "### Measuring the state of a single qubit in a circuit (in terms of its y angle)\n",
    "Recall that the value returned is in relation to the H state, which is zero,<br/>\n",
    "with rotations to the left interpretaed as negative values, and rotatations to the right as positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3b47f-ce5b-4426-88ac-82750071e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Runs a circuit with a single qubit measured and returns its angular position\n",
    "#   Recall the figure explaining encoding\n",
    "\n",
    "def single_qubit_angle_meas(qc, backend, shots=10000):\n",
    "    job = backend.run(qc, shots=shots)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(qc)\n",
    "    \n",
    "    counts0 = counts['0'] if '0' in counts.keys() else 0\n",
    "    counts1 = counts['1'] if '1' in counts.keys() else 0\n",
    "    p0 = counts0/(counts0+counts1)\n",
    "    p1 = counts1/(counts0+counts1)\n",
    "    amp0 = np.sqrt(p0)\n",
    "    amp1 = np.sqrt(p1)\n",
    "\n",
    "    meas_angle = 2*np.arccos(amp0)-np.pi/2\n",
    "    return meas_angle\n",
    "\n",
    "# Test\n",
    "# qc = QuantumCircuit(2, 1)\n",
    "# qc.ry(np.pi/2, 0)\n",
    "# qc.ry(np.pi/4, 1)\n",
    "# qc.measure(1, 0)\n",
    "# print()\n",
    "# display(qc.draw(\"latex\", style=\"iqp\", scale=1))\n",
    "# angle = single_qubit_angle_meas(qc, backend)\n",
    "# round(angle / np.pi, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406bd334-6735-4657-8741-d7f48b2c0242",
   "metadata": {},
   "source": [
    "### Constants guiding QAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fe634-04a6-42cf-b38f-fd88c4e37e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps=2\n",
    "ent='sca' # linear, reverse_linear, full, circular, sca, pairwise\n",
    "num_qubits = wind_size\n",
    "num_trash = 3\n",
    "num_latent = num_qubits-num_trash\n",
    "cost_type = 'zeroes' # min1s, swap, zeroes\n",
    "cost_yscale = 'linear' # linear, log\n",
    "epochs = 500 \n",
    "noise = noise_ts # Noise ratio that has already been added to noisy input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cb5635-3292-41de-bd3d-16bdfa4142ed",
   "metadata": {},
   "source": [
    "### Defining structures of training and testing models and their components\n",
    "*Note that the trainnig model will be used further, however, the testting model is used only as a reference for its structural properties. The actual testing models will be generated dynamically.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcbaed-b1eb-409b-9661-bb5de283fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models structures\n",
    "keep_encoder=False\n",
    "train_qae_qc, in_params, enc_params, dec_params, all_weight_params = \\\n",
    "    train_qae(num_latent, num_trash, reps=reps, ent=ent, in_seq_label='N', in_seq_name='Noisy Input', keep_encoder=keep_encoder)\n",
    "\n",
    "train_qae_qc = train_qae_qc.decompose()\n",
    "print(f'Encoder characteristics: \\n\\n'+\n",
    "      f'\\ttraining windows={len(y_train_enc)}\\n'+\n",
    "      f'\\tvalidation windows={len(y_valid_enc)}\\n'+\n",
    "      f'\\tinputs={len(in_params)}\\n'+\n",
    "      f'\\tkeep_encoder={keep_encoder}\\n'+\n",
    "      f'\\tweights={len(all_weight_params)}\\n'+\n",
    "      f'\\ttrash layer={num_trash}\\n'+\n",
    "      f'\\tlatent layer={num_latent}\\n'+\n",
    "      f'\\ttraining qubits={len(train_qae_qc.qubits)}\\n'+\n",
    "      f'\\ttesting qubits={len(train_qae_qc.qubits)}\\n'+\n",
    "      f'\\treps={reps}\\n'+\n",
    "      f'\\tent={ent}\\n'+\n",
    "      f'\\tnoise={noise}\\n'+\n",
    "      f'\\n'+\n",
    "      f'\\tcost type={cost_type}\\n'+\n",
    "      f'\\tcost yscale={cost_yscale}\\n'+\n",
    "      f'\\tsamples={y_train_enc.shape[0]}\\n'+\n",
    "      f'\\tdevice={device}\\n'+\n",
    "      f'\\tepochs={epochs}\\n'+\n",
    "      ''\n",
    "     )\n",
    "\n",
    "# print(f'\\nTraining autoencoder:')\n",
    "# print(f'\\nData parameters:\\n{in_params}')\n",
    "# print(f'\\nEncoder parameters:\\n{enc_params}')\n",
    "# if not keep_encoder:\n",
    "#     print(f'\\nDecoder parameters:\\n{dec_params}')\n",
    "# print(f'\\nAll training parameters:\\n{all_weight_params}')\n",
    "\n",
    "print('')\n",
    "display(train_qae_qc.draw(\"latex\", style=\"iqp\", scale=2))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a2d2a-c2ae-44ce-8dd0-4024997e808f",
   "metadata": {},
   "source": [
    "### Preparing data for full-QAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28463a9-b8bf-45d6-995d-eb57404da6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preparing data for training\n",
    "#   - First half of each row is to fill in the noisy input block\n",
    "#   - Second half of each row is to fill the expected pure output block\n",
    "\n",
    "# Testing full-QAE with noise, but no separate Decoder\n",
    "y_train_pure_and_noisy = []\n",
    "for (y_noisy, y_pure) in zip(y_train_noisy_enc, y_train_enc):\n",
    "    y_train_pure_and_noisy.append(list(y_noisy)+list(y_pure))\n",
    "y_train_pure_and_noisy = np.array(y_train_pure_and_noisy)\n",
    "\n",
    "print(f'\\nNoisy training data:\\n{y_train_noisy_enc[0:3]}')\n",
    "print(f'\\nPure training data:\\n{y_train_enc[0:3]}')\n",
    "print(f'\\nNoisy+pure training data:\\n{y_train_pure_and_noisy[0:3]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d297281-752c-462b-ab2d-681f674d2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing paramers assignment\n",
    "\n",
    "p_dict = []\n",
    "p_no = 0\n",
    "for p in in_params: #y_train_pure_and_noisy:\n",
    "    p_dict.append(y_train_pure_and_noisy[0][p_no])\n",
    "    # print(f'{p}={p_dict[p_no]}')\n",
    "    p_no += 1\n",
    "# print()\n",
    "\n",
    "init_pt = algorithm_globals.random.random(len(all_weight_params))\n",
    "p_no = 0\n",
    "for p in all_weight_params:\n",
    "    p_dict.append(init_pt[p_no])\n",
    "    # print(f'{p}={p_dict[p_no]}')\n",
    "    p_no += 1\n",
    "# print()\n",
    "\n",
    "qc=train_qae_qc\n",
    "qc=qc.assign_parameters(p_dict)\n",
    "qc.draw(\"latex\", style=\"clifford\", scale=1, fold=-1) # style=clifford/iqp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74851d36-3cba-4cd8-bd6c-1e906a682be4",
   "metadata": {},
   "source": [
    "### File names to be used for saving results\n",
    "Files to store modelinitialisation parameters, original input data, measured input data, QAE recovered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146c0c4-d31c-430c-bbb3-2215bab4648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'results'\n",
    "init_file_name = f'qae_wangle_lat{num_latent}_tr{num_trash}_reps{reps}_{ent}_p{len(all_weight_params)}_err{noise}_{cost_type}_init.json'\n",
    "inorg_file_name = f'qae_wangle_lat{num_latent}_tr{num_trash}_reps{reps}_{ent}_p{len(all_weight_params)}_err{noise}_{cost_type}_org.json'\n",
    "inmeas_file_name = f'qae_wangle_lat{num_latent}_tr{num_trash}_reps{reps}_{ent}_p{len(all_weight_params)}_err{noise}_{cost_type}_inm.json'\n",
    "outrec_file_name = f'qae_wangle_lat{num_latent}_tr{num_trash}_reps{reps}_{ent}_p{len(all_weight_params)}_err{noise}_{cost_type}_out.json'\n",
    "history_file_name = f'qae_wangle_lat{num_latent}_tr{num_trash}_reps{reps}_{ent}_p{len(all_weight_params)}_err{noise}_{cost_type}_hist{epochs}.json'\n",
    "history_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868874b",
   "metadata": {},
   "source": [
    "### Setting the initial point\n",
    "Since model training may take a long time we have already pre-trained the model for some iterations and saved the pre-trained weights. We'll continue training from that point by setting `initial_point` to a vector of pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_starting_point = False\n",
    "\n",
    "if saved_starting_point:\n",
    "    ### Using previously saved init point\n",
    "    print(f'Using previously saved init parameters from file \"{SAVE_PATH}/{init_file_name}\"')\n",
    "\n",
    "    try:\n",
    "        f = open(f'{SAVE_PATH}/{init_file_name}', 'r')\n",
    "    except OSError:\n",
    "        print(f'Could not open/read file: {SAVE_PATH}/{init_file_name}')\n",
    "        sys.exit()\n",
    "    with f:\n",
    "        initial_point = json.load(f)\n",
    "        history_file_name = f'{history_file_name[:-5]}_hist{epochs}.json'\n",
    "        print(f'New history file will be created: \"{SAVE_PATH}/{history_file_name}\"')\n",
    "else:\n",
    "    ### Using a random init point\n",
    "    print(f'Random init parameters to be saved to file \"{SAVE_PATH}/{init_file_name}\"')\n",
    "    initial_point = algorithm_globals.random.random(len(all_weight_params))\n",
    "    print(f'History file will be created: \"{SAVE_PATH}/{history_file_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a0c03",
   "metadata": {},
   "source": [
    "By minimizing this cost function, we can thus determine the required parameters to compress our noisy series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d61cfb-e960-47bc-aeb0-ce819a7e0b9b",
   "metadata": {},
   "source": [
    "### QAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5c4da-2414-4a15-940a-41e65fe79f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility\n",
    "\n",
    "def identity_interpret(x):\n",
    "    return x\n",
    "\n",
    "first_only = lambda x: x % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24422e74-354f-4edb-8b26-302bbbcb7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test\n",
    "\n",
    "sample_qnn = SamplerQNN(\n",
    "    circuit=train_qae_qc,\n",
    "    input_params=in_params,\n",
    "    weight_params=all_weight_params,\n",
    "    interpret=identity_interpret,\n",
    "    output_shape=2**train_qae_qc.num_qubits,\n",
    "    sampler=sampler\n",
    ")\n",
    "sample_data = y_train_pure_and_noisy[0:5]\n",
    "\n",
    "start = time.time()\n",
    "probs = sample_qnn.forward(sample_data, initial_point)\n",
    "elapsed = time.time() - start\n",
    "print(f'Forward pass result for SamplerQNN:\\n{probs}.  \\nShape: {probs.shape}, Time: {elapsed}')\n",
    "print(f'Cost = 1-P(|0>^n) = {1-np.sum(probs[:, 0]) / sample_data.shape[0]} (to be minimised)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_required = True\n",
    "\n",
    "if training_required:\n",
    "    \n",
    "    print('Training initiated, optimum parameters will be calculated')\n",
    "    \n",
    "    qnn = SamplerQNN(\n",
    "        circuit=train_qae_qc,\n",
    "        input_params=in_params,\n",
    "        weight_params=all_weight_params,\n",
    "        interpret=identity_interpret,\n",
    "        output_shape=2**train_qae_qc.num_qubits,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    opt = COBYLA(maxiter=epochs) # COBYLA, NELDER_MEAD, SPSA\n",
    "    cost_func_tswind = Cost(y_train_pure_and_noisy, opt, initial_point, shuffle=True, \n",
    "                            cost_type=cost_type, yscale=cost_yscale)\n",
    "    opt_result = cost_func_tswind.optimize()\n",
    "    optimum_parameters = opt_result.x\n",
    "    minimum_cost = opt_result.fun\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # Print run statistics\n",
    "    print(f'{device} Fit ('+\n",
    "          f'{y_train_pure_and_noisy.shape[0]} samples, '+\n",
    "          f'{reps} reps, '+\n",
    "          f'\"{ent}\" ent, '+\n",
    "          f'{num_latent}+{num_trash} qubits, '+\n",
    "          f'{len(all_weight_params)} params, '+\n",
    "          f'{epochs} epochs): '+\n",
    "          f'{round(minimum_cost, 5)} min cost, '+\n",
    "          f'{elapsed:0.2f} sec')\n",
    "\n",
    "elif saved_starting_point:\n",
    "    optimum_parameters = initial_point\n",
    "    print('Training skipped, previously saved optimum parameters will be used here')\n",
    "else:\n",
    "    optimum_parameters = initial_point\n",
    "    print('Training skipped, optimum parameters were generated randomly')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdf729-d149-440b-82af-17dc5c837b35",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "Note that all components of a test circuit will be built in the testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f3c53-9918-4427-9dbc-6822ec35668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select a backend\n",
    "\n",
    "backend = Aer.get_backend('aer_simulator_statevector')\n",
    "# backend = Aer.get_backend('aer_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6619504-6bf1-4506-b9c6-c2381f13d30e",
   "metadata": {},
   "source": [
    "### QAE calculation and analysis of the selected TS windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb478d3-a844-4963-8a87-fff09705a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select a collection of windows to test\n",
    "\n",
    "# sel_wind_set = list(range(30))\n",
    "# sel_wind_set = [1, 2, 3, 4, 5, 10, 20, 21, 22, 23, 30]\n",
    "# sel_wind_set = [*range(0, 10)]+[*range(30, 50, 2)]+[*range(60, 75, 2)]\n",
    "# sel_wind_set = [*range(0, y_valid_enc.shape[0], 3)]\n",
    "# sel_wind_set = [*range(50, 100, 2)]\n",
    "# sel_wind_set = [*range(50, 100, 1)]\n",
    "# sel_wind_set = [*range(50)]\n",
    "sel_wind_train_set = [*range(1, 20, 2)]\n",
    "sel_wind_valid_set = [*range(len(y_valid_enc))]\n",
    "\n",
    "print(f'Selected {len(sel_wind_train_set)} training windows to process')\n",
    "print(f'Selected {len(sel_wind_valid_set)} validation windows to process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29cbe98-55b2-44e9-a8b9-f60c879d3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generation of QAE results for the selected windows\n",
    "\n",
    "### Analyses a sample of windows, QAE(in) -> recons\n",
    "### winds_pure: a list/array of TS windows\n",
    "### sel_wind_set: a list of the selected windows indeces\n",
    "### returns: dictionaries of a subset of original, measured, and reconstructured windows\n",
    "###          the keys correspond to windows sequence position in a TS\n",
    "\n",
    "def qae_analyse_sample(sel_wind_set, winds_pure, winds_noise=None):\n",
    "    print(f'Processed windows: ', end=' ')\n",
    "\n",
    "    in_org_set = {}\n",
    "    in_meas_set = {}\n",
    "    out_reconstr_set = {}\n",
    "\n",
    "    for wind_idx in range(len(sel_wind_set)):\n",
    "    \n",
    "        sel_wind = sel_wind_set[wind_idx]\n",
    "        if winds_noise is None:\n",
    "            wind = winds_pure[sel_wind] # Noisy data was not provided so use pure-to-pure analysis\n",
    "            in_org_set[sel_wind] = list(wind)\n",
    "        else:\n",
    "            wind = winds_noise[sel_wind] # Use noisy window for manipulation\n",
    "            in_org_set[sel_wind] = list(winds_pure[sel_wind]) # But add pure window for reference\n",
    "    \n",
    "        ### Find the QAE input window state vector representation (as measured)\n",
    "        org_meas = []\n",
    "        for meas_q in range(len(wind)):\n",
    "            org_qc, _ = sequence_encoder(num_latent + num_trash, wind_size, classreg=True, meas_q=meas_q)\n",
    "            org_qc = org_qc.assign_parameters(wind)\n",
    "            meas_angle = single_qubit_angle_meas(org_qc, backend, shots=10000)\n",
    "            org_meas.append(meas_angle)\n",
    "    \n",
    "        ### Find the QAE resulting window state vector representation\n",
    "        out_meas = []\n",
    "        for meas_q in range(len(wind)):\n",
    "            param_values = np.concatenate((wind, optimum_parameters))\n",
    "    \n",
    "            out_qc, _, _, _ = qae(num_latent, num_trash, reps=reps, ent=ent, classreg=True, keep_encoder=False, meas_q=meas_q)     \n",
    "            out_qc = out_qc.assign_parameters(param_values)\n",
    "            out_qc = out_qc.decompose().decompose()\n",
    "            meas_angle = single_qubit_angle_meas(out_qc, backend, shots=10000)\n",
    "            out_meas.append(meas_angle)\n",
    "    \n",
    "        ### Add window results\n",
    "        in_meas_set[sel_wind] = org_meas\n",
    "        out_reconstr_set[sel_wind] = out_meas    \n",
    "    \n",
    "        print(f'{sel_wind}', end=' ')\n",
    "    \n",
    "    print('End\\n')\n",
    "    return in_org_set, in_meas_set, out_reconstr_set\n",
    "\n",
    "# load_qae_results = False\n",
    "\n",
    "# if load_qae_results:\n",
    "\n",
    "#     ### Loading previously saved original window data, measured input and reconstructed data\n",
    "\n",
    "#     try:\n",
    "#         inorg_file = open(inorg_file_name, 'r')\n",
    "#         inmeas_file = open(inmeas_file_name, 'r')\n",
    "#         outrec_file = open(outrec_file_name, 'r')\n",
    "#     except OSError:\n",
    "#         print(f'Could not open/read results files')\n",
    "#         sys.exit()\n",
    "#     with inorg_file, inmeas_file, outrec_file:\n",
    "#         in_org_set = json.load(inorg_file)\n",
    "#         in_meas_set = json.load(inmeas_file)\n",
    "#         out_reconstr_set = json.load(outrec_file)\n",
    "\n",
    "#     print(f'Loaded windows: {\" \".join(in_org_set.keys())} End')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f54cff-2b4d-45db-ad86-9b64cf1b746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyse samples of training and validation data\n",
    "in_org_train_set, in_meas_train_set, out_reconstr_train_set = \\\n",
    "    qae_analyse_sample(sel_wind_train_set, y_train_enc, y_train_noisy_enc) # Noise vs Pure\n",
    "in_org_valid_set, in_meas_valid_set, out_reconstr_valid_set = \\\n",
    "    qae_analyse_sample(sel_wind_valid_set, y_valid_enc, y_valid_noisy_enc) # Noise vs Pure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e333e48-cbf1-421f-9317-4abcf7bc786e",
   "metadata": {},
   "source": [
    "### Reporting of QAE accuracy\n",
    "Several model performance metrics can be calculated based on the selection of TS windows.<br/>\n",
    "In the left column we have metrics comparing QAE inputs with the same but quantum measured inputs.<br/>\n",
    "In the right column we have metrics comparing QAE inputs with its outputs - this is what we are intereted in.<br/>\n",
    "The left column is for your reference to see the impact of measurement on the QAE precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0de84-5620-4f09-9007-4f2fc3fe881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_report(in_org_set, out_reconstr_set, in_meas_set, title='Precision of Results',\n",
    "                   trim_left = 0, trim_right = 0):\n",
    "    \n",
    "    print(f'\\n{title}\\n')\n",
    "\n",
    "    r2_inorg_incalc = r2_tswin(in_org_set, in_meas_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    r2_inorg_outrec = r2_tswin(in_org_set, out_reconstr_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    print(f'\\tR2(in_org, in_calc) =\\t{np.round(r2_inorg_incalc, 3)}, '+\n",
    "          f'\\tR2(in_org, out_rec) =\\t{np.round(r2_inorg_outrec, 3)}')\n",
    "\n",
    "    rms_inorg_incalc = rms_tswin(in_org_set, in_meas_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    rms_inorg_outrec = rms_tswin(in_org_set, out_reconstr_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    print(f'\\tRMS(in_org, in_calc) =\\t{np.round(rms_inorg_incalc, 3)}, '+\n",
    "          f'\\tRMS(in_org, out_rec) =\\t{np.round(rms_inorg_outrec, 3)}')\n",
    "\n",
    "    mae_inorg_incalc = mae_tswin(in_org_set, in_meas_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    mae_inorg_outrec = mae_tswin(in_org_set, out_reconstr_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    print(f'\\tMAE(in_org, in_calc) =\\t{np.round(mae_inorg_incalc, 3)}, '+\n",
    "          f'\\tMAE(in_org, out_rec) =\\t{np.round(mae_inorg_outrec, 3)}')\n",
    "\n",
    "    mape_inorg_incalc = mape_tswin(in_org_set, in_meas_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    mape_inorg_outrec = mape_tswin(in_org_set, out_reconstr_set, trim_left=trim_left, trim_right=trim_right)\n",
    "    print(f'\\tMAPE(in_org, in_calc) =\\t{np.round(mape_inorg_incalc, 3)}, '+\n",
    "          f'\\tMAPE(in_org, out_rec) =\\t{np.round(mape_inorg_outrec, 3)}\\n')\n",
    "\n",
    "    return r2_inorg_incalc, r2_inorg_outrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b75867-3a5c-4fb1-b98a-9904407a0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_inorg_train_incalc, r2_inorg_train_outrec = \\\n",
    "    accuracy_report(in_org_train_set, in_meas_train_set, out_reconstr_train_set, title='Training Accuracy')\n",
    "r2_inorg_valid_incalc, r2_inorg_valid_outrec = \\\n",
    "    accuracy_report(in_org_valid_set, in_meas_valid_set, out_reconstr_valid_set, title='Validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba417e-ef30-4f97-a4f3-07a0db836b96",
   "metadata": {},
   "source": [
    "### Ploting sample QAE results\n",
    "Note the edge distortion, which occurs either at the window's beginning, or more commonly at the end, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606daaf-3784-46cf-b0ef-8f2e5f3ea525",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot all the selected windows and their recovered data\n",
    "\n",
    "def qae_plot_winds(in_org_set, in_meas_set, out_reconstr_set, plot_no=None):\n",
    "    \n",
    "    sorted_keys = sorted(in_org_set.keys())\n",
    "    if plot_no == None:\n",
    "        plot_no = len(sorted_keys)\n",
    "        \n",
    "    for sel_wind in sorted_keys:\n",
    "\n",
    "        if plot_no == 0:\n",
    "            break\n",
    "    \n",
    "        # Retrieve window data\n",
    "        print('\\n')\n",
    "        wind = in_org_set[sel_wind]\n",
    "        org_meas = in_meas_set[sel_wind]\n",
    "        out_meas = out_reconstr_set[sel_wind]    \n",
    "        \n",
    "        # Plot prepared data\n",
    "        plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "        plt.title(f'Original and measured input vs reconstructed data, within window {sel_wind}')\n",
    "        plt.xlabel(\"Data points\")\n",
    "        plt.ylabel(\"Inter-point differences\")\n",
    "        # plt.xlim(lb, ub)\n",
    "        \n",
    "        # Plot target function\n",
    "        plt.plot([x for x in range(len(wind))], wind, color='royalblue', label='Original data')\n",
    "        plt.plot([x for x in range(len(wind))], wind, marker='o', color='cornflowerblue', linestyle='None')\n",
    "        plt.plot([x for x in range(len(wind))], org_meas, color='darkorange', label='Measured data')\n",
    "        plt.plot([x for x in range(len(wind))], org_meas, marker='o', color='orange', linestyle='None')\n",
    "        plt.plot([x for x in range(len(wind))], out_meas, color='red', label='Reconstructed data')\n",
    "        plt.plot([x for x in range(len(wind))], out_meas, marker='o', color='tomato', linestyle='None')\n",
    "        plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.2),\n",
    "                  ncol=3, fancybox=True, shadow=True)\n",
    "        plt.show()\n",
    "\n",
    "        plot_no -= 1\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb0b53-20bb-410e-9e66-6a44d062be4a",
   "metadata": {},
   "source": [
    "#### Testing noise to noise - can we believe what we see!\n",
    "If the red reconstructed curve follow the blue noise curve given on input then we have a problem!<br/>\n",
    "The yellow control curve, which just measures the noisy data, should follow the provided noisy input.<br/>\n",
    "If the red curve is consistently different from both the blue and yellow lines, then it is all great,<br/>\n",
    "as it means the full-QAE has learnt not to follow what was given on input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2eec9d-ed7a-4c15-a28c-7d7b811a939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We pretend that the noisy data is pure, so blue and yellow lines follow noise\n",
    "in_org_valid_noisy_set, in_meas_valid_noisy_set, out_reconstr_valid_noisy_set = \\\n",
    "    qae_analyse_sample(sel_wind_valid_set, y_valid_noisy_enc) # Noise vs Pure\n",
    "qae_plot_winds(in_org_valid_noisy_set, in_meas_valid_noisy_set, out_reconstr_valid_noisy_set, plot_no=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f58f6-8088-405f-9a68-dc40cdabfdbb",
   "metadata": {},
   "source": [
    "#### Plotting results of analysis performed on training data (previously seen by the full-QAE)\n",
    "The blue line shows pure data that was given on output during training.</br>\n",
    "The red curve was reconstructed from the noisy data given on input (not shown here).<br/>\n",
    "The yellow control curve measures the pure data, it follows the blue curve, the best it can.<br/>\n",
    "The red curve should follow the blue pure data and its variance should not be much different from the yellow lines,<br/>\n",
    "as it means it has learnt to recover pure data from noise given on input!<br/>\n",
    "These charts only show that the model has good memory of data shown in training, subject to measurement error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784311bc-1196-4174-943f-678a94378148",
   "metadata": {},
   "outputs": [],
   "source": [
    "qae_plot_winds(in_org_train_set, in_meas_train_set, out_reconstr_train_set, plot_no=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3bd2f8-2648-4352-a78e-5ae6106b1ccf",
   "metadata": {},
   "source": [
    "#### Plotting results of analysis performed on validation data (not seen by the full-QAE)\n",
    "The blue line shows pure data that was given on output during training.</br>\n",
    "The red curve was reconstructed from the noisy data given on input (not shown here).<br/>\n",
    "The yellow control curve measures the pure data, it follows the blue curve, the best it can.<br/>\n",
    "The red curve should follow the blue pure data and its variance should not be much different from the yellow lines,<br/>\n",
    "as it means it has learnt to recover pure data from noise given on input!<br/>\n",
    "These charts show that the model can generalise away from data shown in training, subject to measurement error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0cc9b-8fe4-4029-8140-7c0988de0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "qae_plot_winds(in_org_valid_set, in_meas_valid_set, out_reconstr_valid_set, plot_no=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a49b22-10e9-42e1-a2d3-bb4dea7e0c3e",
   "metadata": {},
   "source": [
    "### Accuracy of results after manual removal of edge distortion in a series windows\n",
    "Based on visual inspection of the QAE results, we can observe that the QAE results are distored at the edges.<br/>\n",
    "So it is possibe to exclude a few data points from each data window, and hence improve the model accuracy.<br/><br/>\n",
    "In the left column we have metrics comparing QAE inputs with the same but quantum measured inputs.<br/>\n",
    "In the right column we have metrics comparing QAE inputs with its outputs - this is what we are intereted in.<br/>\n",
    "The left column is for your reference to see the impact of measurement on the QAE precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29713a5d-cdc8-4a5d-a690-fab420bdeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Present some statistics on the sample, after removing the edge distortion\n",
    "trim_left = 0\n",
    "trim_right = 2\n",
    "\n",
    "r2_adj_inorg_train_incalc, r2_adj_inorg_train_outrec = accuracy_report(in_org_train_set, in_meas_train_set, out_reconstr_train_set, \n",
    "                title='Training Accuracy', trim_left=trim_left, trim_right=trim_right)\n",
    "r2_adj_inorg_valid_incalc, r2_adj_inorg_valid_outrec = accuracy_report(in_org_valid_set, in_meas_valid_set, out_reconstr_valid_set, \n",
    "                title='Validation Accuracy', trim_left=trim_left, trim_right=trim_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fb09b-e4f2-4a16-b83f-8b3017510cc1",
   "metadata": {},
   "source": [
    "### Saving the starting point and calculated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab04c92-dd15-4183-9d40-3370de75e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Files to be saved (when True)\\n')\n",
    "print(f'Optimisation init point: {SAVE_PATH}/{init_file_name}')\n",
    "print(f'Original test windows:   {SAVE_PATH}/{inorg_file_name}')\n",
    "print(f'Measured test windows:   {SAVE_PATH}/{inmeas_file_name}')\n",
    "print(f'Resulting test windows:  {SAVE_PATH}/{outrec_file_name}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6123c03-24ed-4f3f-985f-4de725f6aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the initial point, also save the history file\n",
    "to_be_saved_starting_point = True\n",
    "\n",
    "if to_be_saved_starting_point:\n",
    "    ## Saving the initialisation point\n",
    "    with open(f'{SAVE_PATH}/{init_file_name}', 'w') as f:\n",
    "        json.dump(opt_result.x.tolist(), f)\n",
    "        print(f'Saved optimum parameters as the future starting point in:\\n\\t{init_file_name}')\n",
    "\n",
    "    ### Saving the history file\n",
    "    with open(f'{SAVE_PATH}/{history_file_name}', 'w') as h:\n",
    "        json.dump(cost_func_tswind.objective_func_vals, h)\n",
    "        print(f'Saved optimisation history in:\\n\\t{history_file_name}')\n",
    "else:\n",
    "    print(f'Parameters and history not saved') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4643c90-60a8-4a84-ae7c-50c8c5622343",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save all calculated data points\n",
    "to_be_saved_results = True\n",
    "\n",
    "if to_be_saved_results:\n",
    "    ## Saving results\n",
    "    with open(f'{SAVE_PATH}/{inorg_file_name}', 'w') as f:\n",
    "        json.dump(in_org_valid_set, f)\n",
    "    with open(f'{SAVE_PATH}/{inmeas_file_name}', 'w') as f:\n",
    "        json.dump(in_meas_valid_set, f)\n",
    "    with open(f'{SAVE_PATH}/{outrec_file_name}', 'w') as f:\n",
    "        json.dump(out_reconstr_valid_set, f)\n",
    "    print(f'Saved results in:\\n\\t{inorg_file_name}\\n\\t{inmeas_file_name}\\n\\t{outrec_file_name}')\n",
    "else:\n",
    "    print(f'Sample windows not saved') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ed4c2-ff33-4053-85f9-aac873d25d6d",
   "metadata": {},
   "source": [
    "## Time series integration and plotting\n",
    "The aim is to merge all windows produced in testing into a single sequence, stored as a dictionary. As depicted in the following figure, the integration procedure needs to average all overalapping windows values (white boxes), while considering the step between windows (which creates gaps between overlapping windows) and their edge trimming (which removes distorted values, indicated as gray boxes). \n",
    "\n",
    "<div>\n",
    "    <!--img src=\"attachment:wind-integration.png\" width=\"1000\"-->\n",
    "    <img src=\"../images/wind-integration.png\" width=\"1000\">\n",
    "</div>\n",
    "\n",
    "**Figure: Windows integration procedure**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc13b98-4ff9-4a94-9224-9866f4fa213b",
   "metadata": {},
   "source": [
    "### Windows integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d871e-73fe-4ade-aa0d-300f8c84ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Integrates QAE results stored in a single set of TS widows into a single sequence\n",
    "#   Note: When windows overap their average values will be returned\n",
    "#         When windows are too far apart, separate sub-sequences will be returned\n",
    "#   wind_set: The selected set of TS windows\n",
    "#   trim_left: The number of values to be trimmed from the left edge of each window\n",
    "#   trim_right:  The number of values to be trimmed from the right edge of each window\n",
    "\n",
    "def qae_winds_integ_1(wind_set, trim_left=0, trim_right=0):\n",
    "\n",
    "    # Collect all overalapping values into lists attached to individual data points\n",
    "    vals = {}\n",
    "    for k in sorted(wind_set.keys()):\n",
    "        val_list = wind_set[k]\n",
    "        list_len = len(val_list)\n",
    "        for i in range(list_len):\n",
    "            if (i < trim_left) or (i >= list_len - trim_right):\n",
    "                None # Skip these trimmed values\n",
    "            else:\n",
    "                val_idx = k+i\n",
    "                if val_idx in vals:\n",
    "                    vals[val_idx].append(val_list[i])\n",
    "                else:\n",
    "                    vals[val_idx] = [val_list[i]]\n",
    "\n",
    "    # Collapse all consecutive values into subsequences\n",
    "    # All values apart start new subsequences\n",
    "    seq = {}\n",
    "    next_key = -3\n",
    "    prev_key = 0\n",
    "    for k in sorted(vals.keys()):\n",
    "        next_key += 1\n",
    "        if k == next_key:\n",
    "            seq[prev_key].append(np.average(vals[k]))\n",
    "        else:\n",
    "            prev_key = k\n",
    "            next_key = k\n",
    "            seq[k] = [np.average(vals[k])]\n",
    "            \n",
    "    return seq\n",
    "\n",
    "\n",
    "### Integrates QAE results stored as TS widows into a single sequence\n",
    "#   Note: When windows overap their average values will be returned\n",
    "#         When windows are too far apart, separate sub-sequences will be returned\n",
    "#   in_org_set: The selected set of original TS windows\n",
    "#   in_meas_set: The set of measurements of the original values in TS windows\n",
    "#   out_recons_set: The set of QAE reconstructions for each original TS window\n",
    "#   trim_left: The number of values to be trimmed from the left edge of each window\n",
    "#   trim_right:  The number of values to be trimmed from the right edge of each window\n",
    "\n",
    "def qae_winds_integ(in_org_set, in_meas_set, out_recons_set, trim_left=0, trim_right=0):\n",
    "    in_org_seq = qae_winds_integ_1(in_org_set, trim_left, trim_right)\n",
    "    in_meas_seq = qae_winds_integ_1(in_meas_set, trim_left, trim_right)\n",
    "    out_recons_seq = qae_winds_integ_1(out_recons_set, trim_left, trim_right)\n",
    "    return in_org_seq, in_meas_seq, out_recons_seq\n",
    "\n",
    "### Test window integration\n",
    "# in_org_seq, in_meas_seq, out_recons_seq = qae_winds_integ(in_org_set, in_meas_set, out_reconstr_set, trim_left, trim_right)\n",
    "# [print((k, out_reconstr_set[k])) for k in sorted(out_reconstr_set.keys())]\n",
    "# print()\n",
    "# vals = qae_winds_integ_1(out_recons_seq)\n",
    "# [print((k, vals[k])) for k in sorted(vals.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0433b35-6b3a-4d3e-8ad6-ce5dddf3600a",
   "metadata": {},
   "source": [
    "### Integrated windows plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240608ba-c286-4c49-9a70-c2ccd5a492b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "### Returns the x range for the sequence set\n",
    "def qae_seq_x_range(start, subseq):\n",
    "    return range(start, start+len(subseq))\n",
    "\n",
    "### Plots all three sequences (may consist of separate subsets)\n",
    "def qae_seq_plot(in_org_seq, in_meas_seq, out_recons_seq, \n",
    "                 add_markers=False,\n",
    "                 label_suffix=['', '', ''],\n",
    "                 xlabel='Selected data points', ylabel='Inter-point differences',\n",
    "                 title=f'Original and measured input vs reconstructed data'):\n",
    "    \n",
    "    sorted_keys = sorted(in_org_seq.keys())\n",
    "    \n",
    "    # Plot prepared data\n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    # plt.xlim(lb, ub)\n",
    "        \n",
    "    for sel_wind in sorted_keys:\n",
    "\n",
    "        org_in = in_org_seq[sel_wind]\n",
    "        org_meas = in_meas_seq[sel_wind]\n",
    "        out_meas = out_recons_seq[sel_wind]    \n",
    "        \n",
    "        # Plot target function\n",
    "        plt.plot(qae_seq_x_range(sel_wind, org_in), org_in, color='royalblue')\n",
    "        if add_markers:\n",
    "            plt.plot(qae_seq_x_range(sel_wind, org_in), org_in, marker='o', color='cornflowerblue', linestyle='None')\n",
    "        plt.plot(qae_seq_x_range(sel_wind, org_meas), org_meas, color='darkorange')\n",
    "        if add_markers:\n",
    "            plt.plot(qae_seq_x_range(sel_wind, org_meas), org_meas, marker='o', color='orange', linestyle='None')\n",
    "        plt.plot(qae_seq_x_range(sel_wind, out_meas), out_meas, color='red')\n",
    "        if add_markers:\n",
    "            plt.plot(qae_seq_x_range(sel_wind, out_meas), out_meas, marker='o', color='tomato', linestyle='None')\n",
    "        \n",
    "    # access legend objects automatically created from data\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    \n",
    "    # create manual symbols for legend\n",
    "    line_org = Line2D([0], [0], label=f'Original data {label_suffix[0]}', color='royalblue')\n",
    "    line_meas = Line2D([0], [0], label=f'Measured data {label_suffix[1]}', color='darkorange')\n",
    "    line_recon = Line2D([0], [0], label=f'Reconstructed data {label_suffix[2]}', color='red')\n",
    "    \n",
    "    # add manual symbols to auto legend\n",
    "    handles.extend([line_org, line_meas, line_recon])\n",
    "    \n",
    "    # plt.legend(handles=handles)    \n",
    "    plt.legend(handles=handles, loc='lower center', bbox_to_anchor=(0.5, -0.2),\n",
    "               ncol=3, fancybox=True, shadow=True)\n",
    "    plt.show()\n",
    "\n",
    "    print('\\n')\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c036df-9ea1-4f9e-b0a4-a8b5f36c4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all raw results\n",
    "in_org_train_seq, in_meas_train_seq, out_recons_train_seq = qae_winds_integ(in_org_train_set, in_meas_train_set, out_reconstr_train_set)\n",
    "qae_seq_plot(in_org_train_seq, in_meas_train_seq, out_recons_train_seq, title=f'Original and measured input vs reconstructed training data (with averaged raw results)',\n",
    "             label_suffix=[f'', f'(R2: {np.round(r2_inorg_valid_incalc, 3)})', f'(R2: {np.round(r2_inorg_valid_outrec, 3)})'])\n",
    "\n",
    "in_org_valid_seq, in_meas_valid_seq, out_recons_valid_seq = qae_winds_integ(in_org_valid_set, in_meas_valid_set, out_reconstr_valid_set)\n",
    "qae_seq_plot(in_org_valid_seq, in_meas_valid_seq, out_recons_valid_seq, title=f'Original and measured input vs reconstructed validation data (with averaged raw results)',\n",
    "             label_suffix=[f'', f'(R2: {np.round(r2_inorg_valid_incalc, 3)})', f'(R2: {np.round(r2_inorg_valid_outrec, 3)})'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5aee9-e69e-4be0-834a-da1169de55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all results with distortion trimming\n",
    "in_org_adj_train_seq, in_meas_adj_train_seq, out_recons_adj_train_seq = qae_winds_integ(in_org_train_set, in_meas_train_set, out_reconstr_train_set, trim_left, trim_right)\n",
    "qae_seq_plot(in_org_adj_train_seq, in_meas_adj_train_seq, out_recons_adj_train_seq, title=f'Original and measured input vs reconstructed training data (with edge distortion removed)',\n",
    "             label_suffix=[f'', f'(R2: {np.round(r2_adj_inorg_valid_incalc, 3)})', f'(R2: {np.round(r2_adj_inorg_valid_outrec, 3)})'])\n",
    "\n",
    "in_org_adj_valid_seq, in_meas_adj_valid_seq, out_recons_adj_valid_seq = qae_winds_integ(in_org_valid_set, in_meas_valid_set, out_reconstr_valid_set, trim_left, trim_right)\n",
    "qae_seq_plot(in_org_adj_valid_seq, in_meas_adj_valid_seq, out_recons_adj_valid_seq, title=f'Original and measured input vs reconstructed validation data (with edge distortion removed)',\n",
    "             label_suffix=[f'', f'(R2: {np.round(r2_adj_inorg_valid_incalc, 3)})', f'(R2: {np.round(r2_adj_inorg_valid_outrec, 3)})'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1eb3c",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44364ae",
   "metadata": {},
   "source": [
    "1. A wikipedia page on Autoencoder: https://en.wikipedia.org/wiki/Autoencoder\n",
    "\n",
    "2. Romero, Jonathan, Jonathan P. Olson, and Alan Aspuru-Guzik. \"Quantum autoencoders for efficient compression of quantum data.\" Quantum Science and Technology 2.4 (2017): 045001.\n",
    "\n",
    "3. Swap Test Algorithm: https://en.wikipedia.org/wiki/Swap_test\n",
    "\n",
    "4. Bravo-Prieto, Carlos, \"Quantum autoencoders with enhanced data encoding.\" Machine Learning: Science and Technology, 2, May 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e249894-d2a4-41b0-902a-ec75598e36ed",
   "metadata": {},
   "source": [
    "## Performance Statistics\n",
    "The format of the presented statistics was evolving over time. In the current edition, which is most evident in the reporting for the experiments running on the \"furies-vengence\" machine, the reported details include:\n",
    "- device: Device used to accelerate computation (GPU/CPU)\n",
    "- samples: Number of samples used in training (numeric)\n",
    "- reps: Number of repeated blocks in ansatz (numeric)\n",
    "- ent: Entaglement type (linear, reverse_linear, full, circular, sca, pairwise)\n",
    "- qubits l+t: Number of core ansatz qubits used in QAE testing (numeric latent + trash qubits)\n",
    "- params: Number of trainable parameters (numeric)\n",
    "- epoch: Number of training iterations (numeric)\n",
    "- min cost: Minimum cost achieved in circuit optimisation (numeric)\n",
    "- sec: Elapsed time in seconds used in circuit training (numeric)\n",
    "- R2: R squared providing goodness of fit between the TS window and its reconstruction (0..1)\n",
    "- Trim l+r: R2 measure between windows trimmed to deal with edge distortion (numeric left + right)\n",
    "- comment: Additional remark on the experiment's success (e.g. \"Promissing\" or \"Disappointing\")\n",
    "- colour: Colour siginfying the \"goodness\" of selected experiment's controls (blue=great, red=terrible, magenta=note this, black=FYI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9f38a-58cc-44b1-8429-67ae53e1bd9e",
   "metadata": {},
   "source": [
    "### furies-vengence: ASUS 64Gb RAM\n",
    "- CPU Intel i9, 24 cores, 32 threads, 2.2-3.0-4.3-5.4GHz\n",
    "- GPU NVIDIA GTX 4090, 16384 CUDA Cores, 24 Gb RAM, CUDA V12.3, NVIDIA Driver 545.29.06\n",
    "\n",
    "**Half-QAE Training**\n",
    "\n",
    "<font color=\"blue\">GPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 300 epochs):</font> **0.00301 min cost, 98.32 sec** (R2=0.815, Trim 0+2 R2=0.984, Promising)<br/>\n",
    "<font color=\"blue\">GPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs):</font> **0.00305 min cost, 65.55 sec** (R2=0.838, Trim 0+2 R2=0.986, Promising)<br/>\n",
    "<font color=\"green\">GPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs):</font> **0.03907 min cost, 57.87 sec** (R2=0.764, Trim 0+2 R2=0.967, Test Cost=1-P(|0>^t, no swap))<br/>\n",
    "<font color=\"magenta\">CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs):</font> **0.00379 min cost, 146.40 sec** (R2=0.785, Trim 0+2 R2=0.976, CPU is 0.45 of GPU speed)<br/>\n",
    "<font color=\"blue\">GPU Fit (274 samples, 4 reps, \"sca\" ent, 8+2 qubits, 50 params, 600 epochs):</font> **0.0039 min cost, 236.92 sec** (R2=0.745, Trim 1+1 R2=0.975, Promising)<br/>\n",
    "\n",
    "**Full-QAE Training**\n",
    "\n",
    "GPU Fit (135 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.02601 min cost, 6582.02 sec** (Train: Pure->Pure, Enc/Enc-dg only, Opt to Zero)<br/>\n",
    "&emsp;&emsp;Match: Pure vs Pure (R2=0.707, Trim 0+2 R2=0.923)<br/>\n",
    "\n",
    "GPU Fit (135 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.03173 min cost, 6689.22 sec** (Train: Noise->Pure, Enc/Enc-dg only, Opt to Zero)<br/>\n",
    "&emsp;&emsp;Match: Pure vs Pure (R2=0.768, Trim 0+2 R2=0.989) / Noise vs Noise (R2=0.767, Trim 0+2 R2=0.988) / Noise vs Pure (R2=0.563, Trim 0+2 R2=0.721)<br/>\n",
    "\n",
    "GPU Fit (135 samples, 2 reps, \"sca\" ent, 5+3 qubits, 24 params, 200 epochs): **0.03461 min cost, 6770.68 sec** (Train: Noise->Pure, Enc/Enc-dg only, Opt to Zero)<br/>\n",
    "&emsp;&emsp;Match: Pure vs Pure (R2=0.653, Trim 0+2 R2=0.841) / Noise vs Noise (R2=0.658, Trim 0+2 R2=0.843) / Noise vs Pure (R2=0.509, Trim 0+2 R2=0.66)<br/>\n",
    "\n",
    "GPU Fit (135 samples, 2 reps, \"sca\" ent, 4+4 qubits, 24 params, 200 epochs): **0.04668 min cost, 7057.43 sec** (Train: Noise->Pure, Enc/Enc-dg only, Opt to Zero)<br/>\n",
    "\n",
    "GPU Fit (135 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.06584 min cost, 3874.71 sec** (Train: Noise->Pure, Enc/Enc-dg only, Opt to P(|0>^8))<br/>\n",
    "&emsp;&emsp;Match: Pure vs Pure (R2=0.766, Trim 0+2 R2=0.995) / Noise vs Noise (R2=0.774, Trim 0+2 R2=0.994) / Noise vs Pure (R2=0.536, Trim 0+2 R2=0.698)<br/>\n",
    "\n",
    "GPU Fit (135 samples, 2 reps, \"sca\" ent, 6+2 qubits, 48 params, 200 epochs): **0.15521 min cost, 3592.66 sec** (Train: Noise->Pure, Enc/Dec-dg, Opt to P(|0>^8))<br/>\n",
    "&emsp;&emsp;Epochs 1-200 epocha: Pure vs Pure (R2=0.297, Trim 0+3 R2=0.553) / Noise vs Noise (R2=0.36, Trim 0+3 R2=0.612) / Noise vs Pure (R2=0.165, Trim 0+3 R2=0.398)<br/>\n",
    "GPU Fit (135 samples, 2 reps, \"sca\" ent, 6+2 qubits, 48 params, 200 epochs): **0.08664 min cost, 3891.44 sec** (Train: Noise->Pure, Enc/Dec-dg, Opt to P(|0>^8))<br/>\n",
    "&emsp;&emsp;Epochs 201-400 epocha: Pure vs Pure (R2=0.696, Trim 0+3 R2=0.906) / Noise vs Noise (R2=0.702, Trim 0+3 R2=0.913) / Noise vs Pure (R2=0.558, Trim 0+3 R2=0.742)<br/>\n",
    "\n",
    "<font color=\"blue\">GPU Fit (29 samples, 2 reps, \"sca\" ent, 6+2 qubits, 48 params, 500 epochs):</font> **0.05421 min cost, 2116.93 sec**  (Train: Noise->Pure, Enc/Dec-dg, Opt to P(|0>^8))</br>\n",
    "&emsp;&emsp;training: Noise vs Pure (R2=0.713, Trim 0+2 R2=0.609), validation: Noise vs Pure (R2=0.703, Trim 0+2 R2=0.722, Promising)<br/>\n",
    "\n",
    "\n",
    "**Earlier Half-QAE Training**\n",
    "\n",
    "GPU Fit (275 samples, 2 reps, \"linear\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00884 min cost, 65.01 sec** (R2=404, Trim R2=NA)<br/>\n",
    "GPU Fit (275 samples, 2 reps, \"circular\" ent, 6+2 qubits, 24 params, 200 epochs): **0.014 min cost, 64.83 sec** (R2=-0.303, Trim R2=NA)<br/>\n",
    "GPU Fit (275 samples, 2 reps, \"pairwise\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00629 min cost, 54.41 sec** (R2=0.509, Trim 0+4 R2=0.986)<br/>\n",
    "GPU Fit (275 samples, 2 reps, \"full\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00556 min cost, 68.24 sec** (R2=0.716, Trim 0+3 R2=0.971)<br/>\n",
    "GPU Fit (275 samples, 3 reps, \"sca\" ent, 6+2 qubits, 32 params, 300 epochs): **0.005 min cost, 101.94 sec** (R2=0.766, Trim 2 R2=0.98, Promising)<br/>\n",
    "GPU Fit (274 samples, 2 reps, \"sca\" ent, 8+2 qubits, 30 params, 400 epochs): **0.00459 min cost, 140.45 sec** (R2=0.716, Trim 2 R2=0.76)<br/>\n",
    "GPU Fit (274 samples, 3 reps, \"sca\" ent, 8+2 qubits, 40 params, 500 epochs): **0.00621 min cost, 182.33 sec** (R2=0.814, Trim 2 R2=0.872)<br/>\n",
    "GPU Fit (274 samples, 4 reps, \"sca\" ent, 8+2 qubits, 50 params, 400 epochs): **0.00404 min cost, 157.36 sec** (R2=0.715, Trim 1+1 R2=0.971)<br/>\n",
    "GPU Fit (274 samples, 4 reps, \"circular\" ent, 8+2 qubits, 50 params, 600 epochs): **0.01182 min cost, 243.13 sec** (R2=0.435, Trim R2=NA)<br/>\n",
    "GPU Fit (274 samples, 4 reps, \"pairwise\" ent, 8+2 qubits, 50 params, 600 epochs): **0.00751 min cost, 224.47 sec** (R2=0.629, Trim 0+4 R2=0.857)<br/>\n",
    "\n",
    "\n",
    "### basilisk: Lenovo 32Gb RAM\n",
    "- CPU Intel i7, 4 cores, 8 threads, 2.8GHz - No GPU\n",
    "\n",
    "CPU Fit (110 samples, 6+2 qubits, 32 params): **0.00744 min cost, 226.05 sec**<br/>\n",
    "CPU Fit (275 samples, 6+2 qubits, 32 params, 400 epochs): **0.00512 min cost, 797.54 sec**<br/>\n",
    "CPU Fit (275 samples, 6+2 qubits, 32 params, 250 epochs): **0.00623 min cost, 531.32 sec**<br/>\n",
    "<font color=\"red\">CPU Fit (275 samples, 6+2 qubits, 18 params, 250 epochs):</font> **0.00314 min cost, 308.64 sec** (Bravo-Prieto - terrible)<br/>\n",
    "<font color=\"red\">CPU Fit (275 samples, 6+2 qubits, 18 params, 125 epochs):</font> **0.00407 min cost, 155.59 sec** (Bravo-Prieto - terrible)<br/>\n",
    "<font color=\"red\">CPU Fit (275 samples, 6+2 qubits, 18 params, 125 epochs):</font> **0.00684 min cost, 157.55 sec** (Bravo-Prieto - terrible)<br/>\n",
    "<font color=\"red\">CPU Fit (275 samples, 6+2 qubits, 18 params, 125 epochs):</font> **0.00329 min cost, 154.95 sec** (Bravo-Prieto - terrible)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00359 min cost, 284.36 sec** (R2=-6.629, Trim 0+3 R2=-1.783, Test 2)<br/>\n",
    "\n",
    "### goblin-galore: Tomahawk 64Gb RAM\n",
    "- CPU Intel i7, 6 cores, 12 threads, 3.5GHz - 2 GTX NVIDIA 1080 T1 GPUs, CUDA V12.2, NVIDIA Driver 535\n",
    "- Note that this GPU at 6.1 compute capability is not compatible with Qiskit (cuQuantum requirement: +7 compute capability)\n",
    "\n",
    "CPU Fit (275 samples, 6+2 qubits, 32 params, 400 epochs): **0.00456 min cost, 695.26 sec**<br/>\n",
    "CPU Fit (274 samples, 8+2 qubits, 40 params, 400 epochs): **0.00364 min cost, 2430.50 sec** (Promising)<br/>\n",
    "CPU Fit (274 samples, 6+3 qubits, 45 params, 500 epochs): **0.00907 min cost, 3603.48 sec** (Disappointing)<br/>\n",
    "CPU Fit (275 samples, 5+3 qubits, 40 params, 300 epochs): **0.02233 min cost, 731.32 sec** (Disappointing)<br/>\n",
    "CPU Fit (275 samples, 5+3 qubits, 40 params, 300+100 epochs): **0.01913 min cost, 245.12 sec** (Disappointing)<br/>\n",
    "CPU Fit (275 samples, 6+2 qubits, 24 params, 300 epochs): **0.00334 min cost, 453.17 sec** (Promising, Test 0)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00364 min cost, 309.03 sec** (R2=0.655, Trim 0+2 R2=0.934, Test 1 - Trig vs other Trig)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00364 min cost, 313.68 sec** (R2=-11.302, Trim 0+3 R2=-1.033, Test 2a - Trig vs Poly)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00014 min cost, 296.56 sec** (R2=-10.004, Trim 0+2 R2=-0.94, Test 2b - Poly vs Poly)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 160 epochs): **0.00044 min cost, 236.67 sec** (R2=-12.575, Trim 0+2 R2=-0.874, Test 2c - Poly vs Poly, short)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00752 min cost, 305.49 sec** (R2=0.749, Trim 0+2 R2=0.992, Test 3 - Jitter vs Trig)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.00014 min cost, 306.52 sec** (R2=-8.721, Trim 0+2 R2=-1.014, Test 4a - Linear vs Linear)<br/>\n",
    "CPU Fit (274 samples, 2 reps, \"sca\" ent, 8+2 qubits, 30 params, 200 epochs): **9e-05 min cost, 987.61 sec** (R2=-8.5, Trim 0+2 R2=-5.671, Test 4b - Linear vs Linear)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 6+2 qubits, 24 params, 200 epochs): **0.01954 min cost, 305.30 sec** (R2=0.758, Trim 0+2 R2=0.954, Test 5 Beer)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 5+3 qubits, 24 params, 200 epochs): **0.03795 min cost, 340.04 sec** (R2=0.575, Trim 0+2 R2=0.717, Test 6 Beer)<br/>\n",
    "CPU Fit (275 samples, 2 reps, \"sca\" ent, 4+4 qubits, 24 params, 200 epochs): **0.06599 min cost, 872.53 sec** (R2=0.201, Trim 2+2 R2=0.349, Test Summary Beer)<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d44e07-b6b6-4741-89fe-28f801ba427e",
   "metadata": {},
   "source": [
    "## Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd1766-93c8-43c6-bcff-2eb98be8b309",
   "metadata": {},
   "source": [
    "**Qiskit QAE with Unary Encoding**\n",
    "- V1 Using QAE for anomaly detection (by denoising)\n",
    "    - V1.1 Tested binary encoding, which misses proximity\n",
    "    - V2.0 Created an \"unary\" encoding scheme\n",
    "    - V2.1 Unary encoding tested with various options, not close\n",
    "      - Issues noted:\n",
    "          - Issue 01 (Completed) *Not sure how to interpret the output - cannot be visual*\n",
    "          - Issue 02 (Completed) *Visual match between input and output not close*\n",
    "          - Issue 03 (Completed) *Noise needs to be injected in training*\n",
    "          - Issue 04 (Completed) *Training is getting slow, need to use GPU*\n",
    "          - Issue 05 (Completed) *It is worth testing if an increase of the latent or trash layers could improve the result*\n",
    "      - Action planned:\n",
    "          - *Add Aer GPU*, *Add noise in training*, *Add convolution*, *Create classical solution to compare*\n",
    "    - V2.2 Adding GPU plus encoding test\n",
    "      - Encoding test:\n",
    "          - Tested amplitude encoding. To improve the QAE we may need to focus on other aspects of the model,<br/>\n",
    "            e.g. incorporation of noise and improvement to the ansatz to ensure neighbourhoods are strongly\n",
    "            entangled.\n",
    "      - Several problems installing GPU support, attempt to address Issue 04\n",
    "          - Issue 06 (Completed) *Several problems associated with GPU support*<br/>\n",
    "          - **Fix 06** *Need to install ML 0.7.1+ and Aer 0.13.2+*<br/>\n",
    "            ML 0.7.1 standard installation (no need to install from source anymore)<br/>\n",
    "            Aer 0.13.2 requires CUDA + cuQuantum + cuTensor (Deb)<br/>\n",
    "            - Note that Aer Sampler has a bug and will not work with RawFeatureVector.\n",
    "          - **Fix 04** *With GPU the training speed increased ~2 times\n",
    "    - V2.3 Attempt to move to PuTorch, abandoned for the time being\n",
    "    - V2.4 Changing to angle encoding - relative with Ry over 2pi\n",
    "      - Issues noted:\n",
    "          - Issue 07 (Completed) *Negative numbers not coded properly*</br>\n",
    "      - Action planned:\n",
    "          - *Change encoding as relative from H over pi* - with [-1:0] pi/2 negatives towards |0> and [0:+1] pi/2 positives towards |1>\n",
    "    - V2.5 Completed QAE with angle encoding, lots of fixes\n",
    "      - Fixes completed:\n",
    "          - **Fix 07** *Adopted encoding around H state, up negative, down positive*\n",
    "          - **Fix 02** *Resulting QAE outputs better match the inputs*\n",
    "          - **Fix 01** *With the new encoding, the output is easy to interpret*\n",
    "      - Issues noted:\n",
    "          - *Issue 08* (Partially Completed) *QAE reconstruction has large variance end of windows*, averaging overlapping windows may help\n",
    "          - Issue 09 (Completed) *Need to reconstruct the entire series*, possibly with averaging of overlapping windows\n",
    "      - Action planned:\n",
    "          - Issue 10 (Completed) *Systematically experiment with:* data sets, window size, step size, trash size, qubit no, ansatz reps and entanglement type\n",
    "    - V2.6 Testing various QAE configurations\n",
    "      - Varied the number of qubits (8 was best) and asatz reps (4 was best)\n",
    "      - Issues noted:\n",
    "          - Issue 11 (Completed) *Random seed seems to have little effect on results*\n",
    "          - Issue 12 (Completed) *QAE results tend to be close to zero at the window ends, e.g. 1st and 7th value [0..7]*\n",
    "          - Issue 13 (Completed) *Related to #12, the first window value should not be zero but the diff with the value from the previous window*<br/>\n",
    "            Change the order of processing - first create deltas, then split into windows, change TS value encoding and decoding (no need to delta)\n",
    "    - V2.7 Testing with an older computer Tomahawk, 64Gb RAM, 2 x GeForce GTX 1080 Ti, also testing the enhance encoding of Bravo-Prieto [4]\n",
    "      - Issues noted:\n",
    "          - Issue 14 (Completed) *GPU failed with error:*<br/>\n",
    "            Simulation failed and returned the following error message:<br/>\n",
    "            ERROR:  [Experiment 0] This program was not compiled for SM 61<br/>\n",
    "          - Issue 15 (Completed) *A series of experiments with Bravo-Prieto's algorithm failed to produce any results*\n",
    "      - Fixes completed:\n",
    "          - **Fix 14** Reason (as provided on Slack), CuQuantum does not support GTX 1080 GPUs (cat.SM 61) - may not be fixable, GPU too old\n",
    "          - **Fix 15** Bravo-Prieto algorithm could not be reproduced in any form, and with all possible options - it was abandoned*\n",
    "      - CPU run works well - faster than Lenovo, results are pretty good (as per V2.6)\n",
    "    - V2.8 Fixed incorrect coding of the first window value\n",
    "      - Fixes completed:\n",
    "          - **Fix 11** *Added **seed-simulator** to the backend options for GPU, this may be added for CPU when using AerSampler for CPU*\n",
    "          - **Fix 12-13** *The first window encoded value is now delta of the first value minus the last value from the previous window*<br/>\n",
    "            This was achieved by encoding the entire time series first, before splitting it into windows<br/>\n",
    "            Additional charts were provided to show the original data, encoded sequence, and testing sequence<br/>\n",
    "            QAE results at the edges of a window are non zero\n",
    "      - Issues notes:\n",
    "          - Issue 16 (Completed) *Noted high accuracy of results in the middle of windows, however, the edges are distorted* - related to Issue 08 and issue 12.<br/>\n",
    "            The causes of this phenomenon may be: (1) the ansatz entanglement strategy, (2) position of Swap Test and recovery of the trash space, or (3) the sequential presentation of input.<br/>\n",
    "            A possible approach would be to shuffle data on input, move the position of the trash to the middle, or to reject the values on edges.<bt/>\n",
    "            To test this we need to experiments with larger windows\n",
    "    - V2.9 Tested QAE with windows of size 10 - great results\n",
    "      - Fixes completed:\n",
    "          - Fix 08 (Completed) *When testing with windows of size 8 and 10, the edge inaccuracy persists but shifts*<br/>\n",
    "            This may be the feature of the approach with Swap Test training\n",
    "      - Action planned:\n",
    "        This run was saved and the generated parameters and data will be used to address **Issue 9** (reconstruction of the series)\n",
    "    - V2.10 Started a cleanup of all code\n",
    "      - A test was conducted to create a QAE with 5/6 latent and 3 trash qubits. Its results were disappointing. The notebook, however, was copied to the Runs folder.\n",
    "    - V2.11 Finished cleanup\n",
    "    - V2.12 Adding precision stats of QAE results - R2, RMS, MAE and MAPE, with optional edge trimming of windows to increase precision\n",
    "    - V2.13 Extendend the cost function, now part of the class \"Cost\"<br/>\n",
    "      - Work conducted:\n",
    "          - Implemented class \"Cost\", which allows parameterisation of the function behaviour.\n",
    "          - Attempt 16 (Fully experimented) with the following results:\n",
    "            - *Implemented shuffling of data durinug training, but there was no impact on the edge distortion*\n",
    "            - *Tested variety of entanglement options, \"sco\" was found to be the best, other strategies produced distortions elsewhere and inferior results, so this may still be the culprit*\n",
    "            - *Position of the trash space (and the Swap Test) seems to coincide with the edge distortion, so it could be its cause - needs a separate experiment*\n",
    "    - V2.14 Merging all QAE test windows into a single time series (considering windows step and edge trimming)\n",
    "      - Fixes completed:\n",
    "        - **Fix 05** Experimented with different size of trash / latent area were conducted. with different outcomes, as reported.\n",
    "        - **Fix 08, 16** The edge distortion is possibly linked to the choice of the ansatz, which moves the majority of variance to the edges.\n",
    "          However, elimination of qubits causing distortion may in fact act contrary tothe very idea of QAE restoring the entire range of values in\n",
    "          both latens and trash area. So this must be done with caution.\n",
    "        - **Fix 09** The full series can now be reconstructured, with averaging of overlapping windows, and taking into consideration of window trimming.\n",
    "        - **Fix 10** The systematic tests of the QAE has commensed and will continue.\n",
    "    - V2.15 Test Summary, includes comments on Test 1, Test 2, ..., Test 6, and the Summary notebook\n",
    "      - Observations:\n",
    "        - The previous tests (such as v2.14_merged_ts), focused primarily on perfecting QAE where the trainnig and test sets were drawn from the same data sample.\n",
    "          It seemed that the recovered input patterns had some edge distortion, i.e. increase in variance near qubit 0 and max, removal of which greatly improved the QAE accuracy.\n",
    "          What was not obvious at the time was the fact that the distortion would most commonly occur in the trash area.\n",
    "          This also means that by trimming the trash-related window components carried the majority of noise, and with a small trash area, the latent area was trained to approximate an identity.\n",
    "        - In Test 1, the training sample and a test data were drawn from different sample types, however, both were of an oscillating nature, but of a different complexity and amplitude.\n",
    "          The initial intuition indicated that the recovered data would match the patterns occuring in training data. However, all data recovered would match that of a test data sample -\n",
    "          this is what QAE is in fact supposed to do.\n",
    "        - Test 2a was further testing the hypothesis that QAE would recover the patterns present in a test sample. However, when the types of training and test samples are significantly different, i.e.\n",
    "          sinusuidal and polynomila (almost linear differences betweel data points), the QAE had difficuties replicating the polynomial input. This could possibly be attributed to the QAE input coding\n",
    "          which consisted of qubit rotations, and which favour Fourier style of data processing rather than that typical of regression or polynomial data analysis.\n",
    "          The Test 2b seems to indicate that the QAE is not suitable for learning linear relationships, inspite of excellent cost achieved at the end - note that Test 2c excludes overtrainnig.\n",
    "          It is also worth noting the errors generated by simply measuring the near-linear windows data, their R2 is as low (negative!) as that of the recovered signal!\n",
    "        - Test 3 further confirmed the QAE ability to correctly recover test data, as long as the training data matched its type. However, having used the random oscillations in training\n",
    "          data, it was a great surprise to see the QAE abillity to correctly recover test data. The hypothesis at this point of time was that QAE, without any intelligence, simply replicates i\n",
    "          qubits spanning the latent area.\n",
    "        - Test 4 again looked at polynomial data with near-linear test set. The results show very poor alignment (in terms of R2) between the orginal (but differenced) data and its recovered input.\n",
    "          As before in Test 2, it showed that the error generated by QAE for input recovered on output is of the same magnitude as that generated by the circuit consisting of encoded input alone.\n",
    "          The variance of measured input and the output values around the expected windows values look dramatic, however, this is illusory as the default y range in the chart is very small.\n",
    "          It is worth noting that when looking at the results in the scale of the original data, their MAE and RMS are relatively small.\n",
    "        - Tests 5, 6 and 7 aimed to verify whether or not the QAE was able to abstract the patters learnt from the training data and transfer this knowledge to test data.\n",
    "          Data used for these experiments involved the USA beer sales over several weeks. In the tests, the trash area was progressively enlarged from 2 qubits (leaving 6 qubits in a latent area),\n",
    "          to 3 (with 5 latent qubits) and then 4 (with 4 latent qubits). It was evident that the QAE was able to approximately recover the input, however, the errors would enlarge (as evidenced by\n",
    "          R2, RMSE, MAE and MAPE measurement).\n",
    "        - Test 8 was conducted to ensure that the latent space did not simply produce a copy of the input, which was found not to be the case.\n",
    "        - <font color=\"green\">Test 9 was to replace swap test with in-line test and a new cost function cost=1-P(|0>^t) where t is the size of trash. The approach resulted in faster execution but lower accuracy.</font>\n",
    "        - In summary, the QAE works well. It is able to abstract training data, to allow recovery of previously unseen input data on its output. It is the richness of training data set, which determines\n",
    "          the accuracy of QAE processing with test data, rather than the similarity of the two data sets. However, a completely different types of samples used in training and testing (such as\n",
    "          oscillating vs linear) will prevent QAE to perform with any degree of accuracy.\n",
    "    - V2.16 Development of the full-QAE which could then be used to support noise elimination, and allow the full input vs output comparison\n",
    "      - Issues noted:\n",
    "          - **Issue 17** Training of the full-QAE is ***50 times slower*** than of the half-QAE.\n",
    "            The reasons for this is probably due to the Swap Test on 8 qubits rather than on just the trash space.\n",
    "            Another likely reason is that the Swap Test is comparing arbitrary states rather than |0> states.\n",
    "            Note that a Swap Test may not be effective when the states are close to |+>, which is our encoding of zero\n",
    "            (see Siegelwax, B.N., 2020. The Simplest Way to Compare Single-Qubit Quantum States. Medium).\n",
    "            A more efficient swap test may need to be used. Two possible solutions are considered at this stage:<br/>\n",
    "            (1) train the model in two stages (first as half-QAE for noisy data, then as full-QAE for noisy vs clean data);<br/>\n",
    "            (2) use a destructive swap on one qubit for state swapping and one ancilla for collection and measurement;<br/>\n",
    "            (3) somehow reduce comparison of arbitrary states to zero states.e.g. by rotating all qubits back and then checking for |0>.\n",
    "    - V2.17 Full-QAE with de-noising\n",
    "      - Tests completed:\n",
    "          - Value scaling was tested, large interval generates incorrect TS\n",
    "          - Using full-QAE as a simple encoder S(x) A(x) S(x) with Swap Test to zero works, however, results are not as good as with half-QAE.\n",
    "          - Three tests conducted to test the full-QAE performance with varying sizes of latent space, i.e. 2.17a (6+2), 2.17b (5+3), 2.17c (4+4)\n",
    "      - Issues noted:\n",
    "          - Issue 18 (Completed) Noise embedded in a circuit is not edequate as it is fixed for the entire duration of training.\n",
    "            Noise needs to vary for all instances of training data instead.\n",
    "          - Issue 19 (Completed) Scaling of pure and noisy signals seems to be incorrect, noise seems to have reduced amplitude of the signal.\n",
    "            At the moment noise is added to the original signal. However, after differencing it seems to be distorted - this will affect the work of QAE in denoising.\n",
    "            Perhaps noise needs to be added after differencing, so that it is not subtracted or amplified?\n",
    "          - Issue 20 (Completed) At the moment the full-QAE incorrectly implements a decoder as an encoder-dag, it should be a separate block with its own parameters,\n",
    "            which unfortunately will double execution time and slow it even more.\n",
    "          - Issue 21 (Completed) Full-QAE does not learn to produce clean data from noisy data, it seems to pass noise from input to output.\n",
    "            This may be related to the fact that optimisation error is higher than the discrepancy between noisy and pure data.\n",
    "          - Issue 22 (Completed) Replace the expensive QAE cost function, with a simple P(|0>^n), which can be calculated as the count of all zeros / number of shots.\n",
    "            Idea - aim is to maximise zeros, so measure all qubits, in cost function collect result of forward, check result[0] (all zeros), max this!\n",
    "      - Fixes completed:\n",
    "          - **Fix 03, 18** Now the noise is injected into the TS itself for training or testing\n",
    "          - **Fix 19** Scaling to interval (-1, 1) results in incorrect interpretation of measurements (due to encoding), should not be attempted.\n",
    "            Scaling with (-0.5, +0.5) works better.\n",
    "    - V2.18 Full-QAE with de-noising and new cost function cost=1-P(|0>^q) (q=the number of qubits)\n",
    "      - Observations:\n",
    "          - The new full-QAE is twice as fast\n",
    "          - It takes half the number of qubits\n",
    "          - It is marginally less accurate\n",
    "          - Does not address issue 21 (and possibly 20)\n",
    "      - Fixes completed:\n",
    "          - **Fix 22** The new cost function cost=1-P(|0>^q) (q=the number of qubits) has been implemented and tested.\n",
    "    - V2.19 Full-QAE has a separate encoder and decoder\n",
    "      - Observations:\n",
    "          - The new full-QAE with separate encoder/decoder performs slightly better than encoder/encoder-dg\n",
    "          - It is still unable to reproduce good TS from bad ones (issue 21), perhaps it needs on input a mix of good and noisy data.\n",
    "      - Fixes completed:\n",
    "          - **Fix 20** Full-QAE encoder is followed by an independent decoder-dg, same structure as encoder but in reverse order with different parameters.\n",
    "    - V2.20 Implemented a new cost function which counts the number of 1s in measurements, aiming to eliminate them\n",
    "      - Observations:\n",
    "          - The optimisation very rapidly converges to lower values\n",
    "          - However, it takes lots of iterations to achieve minimum\n",
    "          - However, the minimum does not seem to be what is needed\n",
    "          - The reconstructed curve is not changing much\n",
    "    - V2.21 Going back to cost function 1-P(|0>^n), drastic reduction in data samples used for QAE training and validation\n",
    "      - Observations:\n",
    "          - Data sample was reduced to 29 examples for training and 10 for validation\n",
    "          - The model seems to train quicker and smoother but requires more iterations (500)\n",
    "          - The model actually generalises away from its training data and learns pure data from noise\n",
    "          - Performance metrics are reasonable but not great\n",
    "          - Much better results than before\n",
    "      - Fixes completed:\n",
    "          - **Fix 21** The model learns to reconstruct pure data windows from noisy data\n",
    "      - Future work:\n",
    "          - Test the model performance on other (simpler) data sets\n",
    "          - Test the model performance with the cost function minimising the 1s in measurements\n",
    "          - Try pretraining the encoder with half-QAE and stage decoder training (this may improve the training speed and address the only outstanding **Issue 17**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7441d-aa59-4726-af60-ca1787a69236",
   "metadata": {},
   "source": [
    "# Software in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006922d-333f-47e2-a360-0163fc0a87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep -E 'qiskit|torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit.tools.jupyter\n",
    "\n",
    "# Note that Qiskit Terra and ML were compiled in from sources\n",
    "%qiskit_version_table\n",
    "\n",
    "# As this code was derived from Qiskit tutorial retain the following\n",
    "%qiskit_copyright"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
