{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Building Convolutional Autoencoders in Keras\n",
    "\n",
    "Adapted from: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "By: Jacob Cybulski<br>\n",
    "Date: Sept 2020\n",
    "\n",
    "Adapted From: Francois Chollet<br>\n",
    "Date: 14 May 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Standard libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import tensorflow and check GPU support*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional note that while this notebook executes, you can watch the GPU activity using the operating system utilities, i.e.:**\n",
    "- On Linux: watch -n 5 nvidia-smi\n",
    "- On Windows: nvidia-smi --loop=5\n",
    "\n",
    "**What happens when the GPU disappears? Try in this order:**\n",
    "1. Restart the kernel \n",
    "2. Quit Jupyter Notebook (closing the browser is not enough)\n",
    "3. Kill the \"run-away\" Python process\n",
    "4. Restart the computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import UpSampling2D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "img_ch = 1\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Reshape images for processing\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, img_ch)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, img_ch)\n",
    "input_shape = (img_rows, img_cols, img_ch)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional autoencoder\n",
    "***Note that building autoencoder exceeds capabilities of <font color='blue'>sequential</font> models.<br>\n",
    "Instead we must use <font color='blue'>functional</font> models, which can be arranged in arbitrary ways.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single fully-connected neural layer as encoder and as decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "reg_l1 = 0\n",
    "batch = 128\n",
    "epochs = 300\n",
    "\n",
    "# Model created, note these regularisations:\n",
    "#   BatchNormalization prevents weight going very large or very small\n",
    "#   LeakyReLU also ensures that weights do not get stuck in backpropagation\n",
    "\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(16, (3, 3), padding='same')(input_img) # activation='relu'\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=.001)(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=.001)(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=.001)(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "# why is it so large, it should be much smaller for 10 digits?\n",
    "\n",
    "x = Conv2D(8, (3, 3), padding='same')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=.001)(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=.001)(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=.001)(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create and train a model (val loss with and without reg L1 = 0.097).*<br>\n",
    "*Sample callbacks have been included here, Tensorboard callbacks will slow learning.*<br>\n",
    "*Unfortunately you will not be able using Tensorboard on lab machines.*<br>\n",
    "*You can also experioment with different optimisers and their parameters, e.g. see:*\n",
    "- Callbacks: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "- Optimisers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adadelta, Adam, Nadam\n",
    "\n",
    "log_dir = '/tmp/autoencoder/deep-4'\n",
    "callbacks = [TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True, \n",
    "               embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None,\n",
    "               profile_batch = 100000000),\n",
    "             EarlyStopping(monitor='val_loss', patience=30, verbose=0)]\n",
    "\n",
    "opt_rmsprop = RMSprop(lr=0.005, rho=0.95, momentum=0.01, epsilon=1e-07)\n",
    "opt_adadelta_1 = Adadelta(lr=0.001, rho=0.95, epsilon=1e-07)\n",
    "opt_adadelta_2 = Adadelta(lr=0.05, rho=0.99, epsilon=1e-07)\n",
    "opt_adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "opt_nadam = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "\n",
    "autoencoder.compile(optimizer=opt_nadam, loss='binary_crossentropy')\n",
    "hist = autoencoder.fit(x_train, x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_hist(h, xsize=6, ysize=10):\n",
    "    \n",
    "    # Find what measurements were recorded\n",
    "    meas = h.keys()\n",
    "    \n",
    "    # Prepare plotting\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
    "    \n",
    "    # Plot each measurement\n",
    "    meas_list = []\n",
    "    for m in meas:\n",
    "        plt.plot(h[m])\n",
    "        meas_list.append(m)\n",
    "\n",
    "    # Add info to the plot\n",
    "    ylab = ', '\n",
    "    plt.ylabel(ylab.join(meas_list))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(meas_list) #, loc='upper left')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "plot_hist(hist.history, xsize=8, ysize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the original and predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Let's see if we could now recover the original images from noisy digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Introduce some noise in both training and test data sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is what noisy MNIST look like*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now predict from noisy data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "decoded_noisy_imgs = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "# We can also try recover these digits from the training set\n",
    "# decoded_noisy_imgs = autoencoder.predict(x_train_noisy[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Matplotlib\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_noisy_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**How accurate are these recovered digits?**</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
