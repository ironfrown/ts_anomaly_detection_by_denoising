{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Building Deep Autoencoders in Keras\n",
    "\n",
    "Adapted from: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "By: Jacob Cybulski<br>\n",
    "Date: Sept 2020\n",
    "\n",
    "Adapted From: Francois Chollet<br>\n",
    "Date: 14 May 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Standard libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import tensorflow and check GPU support*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional note that while this notebook executes, you can watch the GPU activity using the operating system utilities, i.e.:**\n",
    "- On Linux: watch -n 5 nvidia-smi\n",
    "- On Windows: nvidia-smi --loop=5\n",
    "\n",
    "**What happens when the GPU disappears? Try in this order:**\n",
    "1. Restart the kernel \n",
    "2. Quit Jupyter Notebook (closing the browser is not enough)\n",
    "3. Kill the \"run-away\" Python process\n",
    "4. Restart the computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep autoencoder\n",
    "***Note that building autoencoder exceeds capabilities of <font color='blue'>sequential</font> models.<br>\n",
    "Instead we must use <font color='blue'>functional</font> models, which can be arranged in arbitrary ways.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single fully-connected neural layer as encoder and as decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "reg_l1 = 0\n",
    "batch = 256\n",
    "epochs = 300\n",
    "\n",
    "# Model\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create and train a model (val loss with and without reg L1 = 0.097).*<br>\n",
    "*Sample callbacks have been included here, Tensorboard callbacks will slow learning.*<br>\n",
    "*Unfortunately you will not be able using Tensorboard on lab machines.*<br>\n",
    "*You can also experioment with different optimisers and their parameters, e.g. see:*\n",
    "- Callbacks: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "- Optimisers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adadelta, Adam, Nadam\n",
    "\n",
    "log_dir = '/tmp/autoencoder/deep-1'\n",
    "callbacks = [TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True, \n",
    "               embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None,\n",
    "               profile_batch = 100000000),\n",
    "             EarlyStopping(monitor='val_loss', patience=30, verbose=0)]\n",
    "\n",
    "opt_rmsprop = RMSprop(lr=0.001, rho=0.9, momentum=0.0, epsilon=1e-07)\n",
    "opt_adadelta_1 = Adadelta(lr=0.001, rho=0.95, epsilon=1e-07)\n",
    "opt_adadelta_2 = Adadelta(lr=0.05, rho=0.99, epsilon=1e-07)\n",
    "opt_adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "\n",
    "autoencoder.compile(optimizer=opt_adadelta_1, loss='binary_crossentropy')\n",
    "hist = autoencoder.fit(x_train, x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_hist(h, xsize=6, ysize=10):\n",
    "    \n",
    "    # Find what measurements were recorded\n",
    "    meas = h.keys()\n",
    "    \n",
    "    # Prepare plotting\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
    "    \n",
    "    # Plot each measurement\n",
    "    meas_list = []\n",
    "    for m in meas:\n",
    "        plt.plot(h[m])\n",
    "        meas_list.append(m)\n",
    "\n",
    "    # Add info to the plot\n",
    "    ylab = ', '\n",
    "    plt.ylabel(ylab.join(meas_list))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(meas_list) #, loc='upper left')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "plot_hist(hist.history, xsize=8, ysize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the original and predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
